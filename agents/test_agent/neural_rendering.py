import torch
import torch.nn as nn
import numpy as np
import torch.nn.functional as F
import torch.autograd.profiler as profiler
import torchvision.transforms as T

from termcolor import colored, cprint
from dotmap import DotMap

import agents.manigaussian_bc2.utils as utils
from agents.manigaussian_bc2.models_embed import GeneralizableGSEmbedNet
from agents.manigaussian_bc2.loss import l1_loss, l2_loss, cosine_loss, ssim
from agents.manigaussian_bc2.graphics_utils import getWorld2View2, getProjectionMatrix, focal2fov
from agents.manigaussian_bc2.gaussian_renderer import render,render_mask, render_mask_gen,render1,render_rgb
from agents.manigaussian_bc2.project_hull import label_point_cloud, points_inside_convex_hull, \
    depth_mask_to_3d, project_3d_to_2d, create_2d_mask_from_convex_hull, merge_arrays, merge_tensors
import visdom
import logging
import einops
import time
import random

# for debugging 
# from PIL import Image
# import cv2 

def PSNR_torch(img1, img2, max_val=1, mask=None):
    """è®¡ç®—ä¸¤å¼ å›¾åƒä¹‹é—´çš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPeak Signal-to-Noise Ratioï¼Œç®€ç§° PSNRï¼‰ã€‚
    PSNR æ˜¯ä¸€ç§å¸¸ç”¨çš„è¡¡é‡å›¾åƒè´¨é‡çš„æŒ‡æ ‡ï¼Œç‰¹åˆ«æ˜¯åœ¨è¯„ä¼°å›¾åƒé‡å»ºã€åŽ‹ç¼©æˆ–åŽ»å™ªç®—æ³•çš„æ€§èƒ½æ—¶ã€‚
    PSNR å€¼è¶Šé«˜ï¼Œè¡¨ç¤ºä¸¤å¹…å›¾åƒè¶Šç›¸ä¼¼ï¼Œå›¾åƒè´¨é‡è¶Šå¥½ã€‚"""
    mse = torch.mean((img1 - img2) ** 2)
    if mse == 0:
        return torch.tensor(100.0).to(img1.device)
    PIXEL_MAX = max_val
    return 20 * torch.log10(PIXEL_MAX / torch.sqrt(mse))


class NeuralRenderer(nn.Module):
    """
    take a voxel, camera pose, and camera intrinsics as input,
    and output a rendered image
    å°†ä½“ç´ ã€æ‘„åƒæœºå§¿æ€å’Œæ‘„åƒæœºæœ¬å¾ä½œä¸ºè¾“å…¥ã€
    å¹¶è¾“å‡ºæ¸²æŸ“å›¾åƒ
    """
    def __init__(self, cfg):
        super(NeuralRenderer, self).__init__()

        self.cfg = cfg
        self.coordinate_bounds = cfg.coordinate_bounds # bounds of voxel grid
        self.W = cfg.image_width
        self.H = cfg.image_height
        self.bg_color = cfg.dataset.bg_color
        self.bg_mask = [0,0,0] #[1,0,0]

        self.znear = cfg.dataset.znear
        self.zfar = cfg.dataset.zfar
        self.trans = cfg.dataset.trans # default: [0, 0, 0]
        self.scale = cfg.dataset.scale
        # å®šä¹‰ç±»åˆ«æ•°
        self.num_classes = 3


        self.use_CEloss =7 # å¸¸ç”¨ï¼š0/7/1  2:ä¸¤ä¸ªç»´åº¦ 7ï¼š3ç»´åº¦-ignore0 5æžç¬‘ç‰ˆlanguageä»£æ›¿mask 6 onlyembed

        # gs regressor åº”è¯¥ä¸ç”¨æ”¹
        self.gs_model = GeneralizableGSEmbedNet(cfg, with_gs_render=True)
        print(colored("[NeuralRenderer] GeneralizableGSEmbedNet is build", "cyan"))

        self.model_name = cfg.foundation_model_name
        self.d_embed = cfg.d_embed
        self.loss_embed_fn = cfg.loss_embed_fn
        self.CrossEntropyLoss = nn.CrossEntropyLoss(reduction='mean') 
        self.criterion_nll = nn.NLLLoss()

        if self.model_name == "diffusion":
            from odise.modeling.meta_arch.ldm import LdmFeatureExtractor
            import torchvision.transforms as T
            self.feature_extractor = LdmFeatureExtractor(
                            encoder_block_indices=(5, 7),
                            unet_block_indices=(2, 5, 8, 11),
                            decoder_block_indices=(2, 5),
                            steps=(0,),
                            captioner=None,
                        )
            self.diffusion_preprocess = T.Resize(512, antialias=True)
            cprint("diffusion feature dims: "+str(self.feature_extractor.feature_dims), "yellow")
        elif self.model_name == "dinov2":
            from agents.manigaussian_bc2.dino_extractor import VitExtractor
            import torchvision.transforms as T
            self.feature_extractor = VitExtractor(
                model_name='dinov2_vitl14',
            )
            self.dino_preprocess = T.Compose([
                T.Resize(224 * 8, antialias=True),  # must be a multiple of 14
            ])
            cprint("dinov2 feature dims: "+str(self.feature_extractor.feature_dims), "yellow")
        else:
            cprint(f"foundation model {self.model_name} is not implemented", "yellow")

        self.lambda_embed = cfg.lambda_embed
        print(colored(f"[NeuralRenderer] foundation model {self.model_name} is build. loss weight: {self.lambda_embed}", "cyan"))

        self.lambda_rgb = 1.0 if cfg.lambda_rgb is None else cfg.lambda_rgb
        print(colored(f"[NeuralRenderer] rgb loss weight: {self.lambda_rgb}", "cyan"))

        self.use_dynamic_field = cfg.use_dynamic_field
        self.field_type = cfg.field_type
        self.mask_gen = cfg.mask_gen
        self.use_nerf_picture = cfg.use_nerf_picture

    def _embed_loss_fn(self, render_embed, gt_embed):
        """
        render_embed: [bs, h, w, 3]
        gt_embed: [bs, h, w, 3]
        """
        if self.loss_embed_fn == "l2_norm":
            # label normalization
            MIN_DENOMINATOR = 1e-12
            gt_embed = (gt_embed - gt_embed.min()) / (gt_embed.max() - gt_embed.min() + MIN_DENOMINATOR)
            loss_embed = l2_loss(render_embed, gt_embed)
        elif self.loss_embed_fn == "l2":
            loss_embed = l2_loss(render_embed, gt_embed)
        elif self.loss_embed_fn == "cosine":
            loss_embed = cosine_loss(render_embed, gt_embed)
        else:
            cprint(f"loss_embed_fn {self.loss_embed_fn} is not implemented", "yellow")
        return loss_embed

    def ele_multip_in_chunks(self, feat_expanded, masks_expanded, chunk_size=5):
        # é€å—å…ƒç´ ä¹˜æ³•è¿ç®—
        result = torch.zeros_like(feat_expanded)
        for i in range(0, feat_expanded.size(0), chunk_size):
            end_i = min(i + chunk_size, feat_expanded.size(0))
            for j in range(0, feat_expanded.size(1), chunk_size):
                end_j = min(j + chunk_size, feat_expanded.size(1))
                chunk_feat = feat_expanded[i:end_i, j:end_j]
                chunk_mask = masks_expanded[i:end_i, j:end_j].float()

                result[i:end_i, j:end_j] = chunk_feat * chunk_mask
        return result

    def mask_feature_mean(self, feat_map, gt_masks, image_mask=None, return_var=False):
        """Compute the average instance features within each mask.
        feat_map: [C=6, H, W]         the instance features of the entire image
        gt_masks: [num_mask, H, W]  num_mask boolean masks
        è®¡ç®—æ¯ä¸ªæŽ©ç å†…çš„å¹³å‡å®žä¾‹ç‰¹å¾ã€‚
        feat_mapï¼š[C=6, H, W]æ•´å¼ å›¾åƒçš„å®žä¾‹ç‰¹å¾
        gt_masks: [num_mask, H, W] num_mask å¸ƒå°”æŽ©ç 
        """
        num_mask, H, W = gt_masks.shape

        # expand feat and masks for batch processing æ‰©å±•æ‰¹é‡å¤„ç†çš„åŠŸèƒ½å’ŒæŽ©ç 
        feat_expanded = feat_map.unsqueeze(0).expand(num_mask, *feat_map.shape)  # [num_mask, C, H, W]
        masks_expanded = gt_masks.unsqueeze(1).expand(-1, feat_map.shape[0], -1, -1)  # [num_mask, C, H, W]
        if image_mask is not None:  # image level mask å›¾åƒçº§æŽ©æ¨¡ (alpha) 
            image_mask_expanded = image_mask.unsqueeze(0).expand(num_mask, feat_map.shape[0], -1, -1)

        # average features within each mask æ¯ä¸ªæŽ©æ¨¡å†…çš„å¹³å‡ç‰¹å¾
        if image_mask is not None:
            masked_feats = feat_expanded * masks_expanded.float() * image_mask_expanded.float()
            mask_counts = (masks_expanded * image_mask_expanded.float()).sum(dim=(2, 3))
        else:
            # masked_feats = feat_expanded * masks_expanded.float()  # [num_mask, C, H, W] may cause OOM
            masked_feats = self.ele_multip_in_chunks(feat_expanded, masks_expanded, chunk_size=5)   # in chuck to avoid OOM  # æŒ‰å—å¤„ç†ä»¥é¿å…å†…å­˜æº¢å‡º
            mask_counts = masks_expanded.sum(dim=(2, 3))  # [num_mask, C]

        # the number of pixels within each mask æ¯ä¸ªæŽ©æ¨¡å†…çš„åƒç´ æ•°
        mask_counts = mask_counts.clamp(min=1)

        # the mean features of each mask æ¯ä¸ªæŽ©æ¨¡çš„å¹³å‡ç‰¹å¾
        sum_per_channel = masked_feats.sum(dim=[2, 3])
        mean_per_channel = sum_per_channel / mask_counts    # [num_mask, C]

        if not return_var: # default
            return mean_per_channel   # [num_mask, C]
        # else:
        #     # calculate variance
        #     # masked_for_variance = torch.where(masks_expanded.bool(), masked_feats - mean_per_channel.unsqueeze(-1).unsqueeze(-1), torch.zeros_like(masked_feats))
        #     masked_for_variance = process_in_chunks(masks_expanded, masked_feats, mean_per_channel, chunk_size=5) # in chunk to avoid OOM

        #     # variance_per_channel = (masked_for_variance ** 2).sum(dim=[2, 3]) / mask_counts    # [num_mask, 6]
        #     variance_per_channel = calculate_variance_in_chunks(masked_for_variance, mask_counts, chunk_size=5)   # in chuck to avoid OOM

        #     # mean and variance
        #     mean = mean_per_channel.mean(dim=1)          # [num_mask]ï¼Œnot used
        #     variance = variance_per_channel.mean(dim=1)  # [num_mask]

        #     return mean_per_channel, variance, mask_counts[:, 0]   # [num_mask, C], [num_mask], [num_mask]

    def cohesion_loss(self, feat_map, gt_mask, feat_mean_stack):
        """intra-mask smoothing loss. Eq.(1) in the paper
        Constrain the feature of each pixel within the mask to be close to the mean feature of that mask.
        æŽ©æ¨¡å†…å¹³æ»‘æŸå¤±ã€‚è®ºæ–‡ä¸­çš„å¼(1)å°†æŽ©æ¨¡å†…æ¯ä¸ªåƒç´ çš„ç‰¹å¾é™åˆ¶ä¸ºæŽ¥è¿‘è¯¥æŽ©æ¨¡çš„å¹³å‡ç‰¹å¾ã€‚
        """
        N, H, W = gt_mask.shape
        C = feat_map.shape[0]
        # expand feat_map [6, H, W] to [N, 6, H, W]
        feat_map_expanded = feat_map.unsqueeze(0).expand(N, C, H, W)
        # expand mean feat [N, 6] to [N, 6, H, W]
        feat_mean_stack_expanded = feat_mean_stack.unsqueeze(-1).unsqueeze(-1).expand(N, C, H, W)
        
        # fature distance     è®¡ç®—ç‰¹å¾è·ç¦»   masked_featï¼šé€šè¿‡å°†æ‰©å±•åŽçš„ç‰¹å¾å›¾ä¸ŽæŽ©ç ç›¸ä¹˜ï¼Œå¾—åˆ°çš„ç»“æžœåªä¿ç•™äº†æŽ©ç ä¸º 1 çš„ä½ç½®ï¼ˆå³ç‰¹å®šå®žä¾‹çš„ç‰¹å¾ï¼‰ï¼Œå…¶ä½™ä½ç½®å°†ä¸º 0ã€‚æœ€ç»ˆå½¢çŠ¶ä»ä¸º [ð‘,6,ð»,ð‘Š][N,6,H,W]ã€‚
        masked_feat = feat_map_expanded * gt_mask.unsqueeze(1)           # [N, 6, H, W]  # [N, 6, H, W]*[N,1,H,W]ï¼Œåªä¿ç•™ gt_mask ä¸º 1 çš„ä½ç½®
        dist = (masked_feat - feat_mean_stack_expanded).norm(p=2, dim=1) # [N, H, W]     # è®¡ç®—æ¯ä¸ªåƒç´ çš„ç‰¹å¾è·ç¦»ï¼Œç»“æžœä¸º [N, H, W]   .norm(p=2, dim=1)ï¼šè¿™ä¸ªæ–¹æ³•è®¡ç®—åœ¨ç‰¹å¾ç»´åº¦ï¼ˆå³é€šé“ç»´åº¦ï¼Œå¤§å°ä¸º6ï¼‰ä¸Šçš„ L2 èŒƒæ•°ï¼ˆæ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰ï¼Œå¾—åˆ°çš„ç»“æžœæ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º [ð‘,ð»,ð‘Š[N,H,W] çš„å¼ é‡ï¼Œè¡¨ç¤ºæ¯ä¸ªæ ·æœ¬çš„æ¯ä¸ªåƒç´ ä¸Žå…¶å¯¹åº”å¹³å‡ç‰¹å¾ä¹‹é—´çš„è·ç¦»ã€‚
        
        # per mask feature distance (loss) æ¯ä¸ªæŽ©æ¨¡ç‰¹å¾è·ç¦»ï¼ˆæŸå¤±ï¼‰
        masked_dist = dist * gt_mask    # [N, H, W] # [N, H, W]ï¼Œåªä¿ç•™ gt_mask ä¸º 1 çš„ä½ç½®
        loss_per_mask = masked_dist.sum(dim=[1, 2]) / gt_mask.sum(dim=[1, 2]).clamp(min=1) # å¯¹æ¯ä¸ª mask çš„è·ç¦»æ±‚å’Œå¹¶å½’ä¸€åŒ–

        return loss_per_mask.mean()


    def separation_loss(self,feat_mean_stack):
        """ inter-mask contrastive loss Eq.(2) in the paper
        Constrain the instance features within different masks to be as far apart as possible.
        è®ºæ–‡ä¸­çš„æŽ©æ¨¡é—´å¯¹æ¯”æŸå¤±æ–¹ç¨‹ï¼ˆ2ï¼‰å°†ä¸åŒè’™ç‰ˆå†…çš„å®žä¾‹ç‰¹å¾é™åˆ¶ä¸ºå°½å¯èƒ½è¿œç¦»
        """
        N, _ = feat_mean_stack.shape  # èŽ·å–ç‰¹å¾å‡å€¼å †æ ˆçš„æ•°é‡ N

        # expand feat_mean_stack[N, 6] to [N, N, C] å°† feat_mean_stack ä»Ž [N, 6] æ‰©å±•åˆ° [N, N, C]
        feat_expanded = feat_mean_stack.unsqueeze(1).expand(-1, N, -1)    # [N, N, C]
        feat_transposed = feat_mean_stack.unsqueeze(0).expand(N, -1, -1)  # [N, N, C]
        
        # distance  è®¡ç®—ç‰¹å¾ä¹‹é—´çš„å¹³æ–¹è·ç¦»
        diff_squared = (feat_expanded - feat_transposed).pow(2).sum(2) # [N, N]
        
        # Calculate the inverse of the distance to enhance discrimination è®¡ç®—è·ç¦»çš„å€’æ•°ä»¥å¢žå¼ºåŒºåˆ†æ€§
        epsilon = 1     # 1e-6  # 1e-6ï¼Œé¿å…é™¤ä»¥é›¶çš„å¸¸æ•°
        inverse_distance = 1.0 / (diff_squared + epsilon)  # [N, N]
        # Exclude diagonal elements (distance from itself) and calculate the mean inverse distance
        # æŽ’é™¤å¯¹è§’å…ƒç´ ï¼ˆè‡ªèº«çš„è·ç¦»ï¼‰ï¼Œå¹¶è®¡ç®—å¹³å‡å€’æ•°è·ç¦»
        mask = torch.eye(N, device=feat_mean_stack.device).bool() # åˆ›å»ºå•ä½çŸ©é˜µæŽ©ç 
        inverse_distance.masked_fill_(mask, 0)                    # å°†å¯¹è§’çº¿å…ƒç´ è®¾ä¸º 0ï¼Œé¿å…å¯¹è‡ªèº«è·ç¦»çš„å½±å“  

        # note: weight   æƒé‡è®¡ç®—
        # sorted by distance  æ ¹æ®è·ç¦»æŽ’åº
        sorted_indices = inverse_distance.argsort().argsort()   # [N, N]ï¼Œå¯¹è·ç¦»è¿›è¡ŒæŽ’åº 
        loss_weight = (sorted_indices.float() / (N - 1)) * (1.0 - 0.1) + 0.1    # scale to 0.1 - 1.0, [N, N]   # å°†æƒé‡ç¼©æ”¾åˆ° 0.1 - 1.0 çš„èŒƒå›´
        # small weight
        # if iteration > 35_000:   # å¦‚æžœè¿­ä»£æ¬¡æ•°å¤§äºŽ 35,000
            # loss_weight[loss_weight < 0.9] = 0.1   # å°†å°äºŽ 0.9 çš„æƒé‡è®¾ä¸º 0.1
        # inverse_distance *= loss_weight     # [N, N] åº”ç”¨æƒé‡

        # final loss
        loss = inverse_distance.sum() / (N * (N - 1))

        return loss

    def _mask_loss_fn(self, render_mask, gt_mask):
        
        if self.use_CEloss == 1:
            render_mask = torch.log(render_mask/ 2 + 0.5)
            # print("render_mask = ",render_mask)
            # render_mask = torch.log(render_mask)
            loss = self.criterion_nll (render_mask, gt_mask)
        elif self.use_CEloss == 2:
            celoss = nn.CrossEntropyLoss(ignore_index=-1)
            loss = celoss(render_mask, gt_mask-1)  
        elif self.use_CEloss == 21:
            celoss = nn.CrossEntropyLoss(reduction='mean')
            loss = celoss(render_mask, gt_mask)  
        elif self.use_CEloss == 7:
            celoss = nn.CrossEntropyLoss(ignore_index=0)
            loss = celoss(render_mask, gt_mask)  
        elif self.use_CEloss == 3:
            rendered_ins_feat = render_mask[0,:,:,:]
            mask_bool = gt_mask[0,:,:,:]
            # (0) compute the average instance features within each mask. [num_mask, 6]
            # rendered_silhouette å³é€æ˜Žåº¦ éœ€è¦renderåšçš„
            feat_mean_stack = self.mask_feature_mean(rendered_ins_feat, mask_bool) #, image_mask=rendered_silhouette)
            # (1) intra-mask smoothing loss. Eq.(1) in the paper
            loss_cohesion = self.cohesion_loss(rendered_ins_feat, mask_bool, feat_mean_stack)
            # (2) inter-mask contrastive loss Eq.(2) in the paper
            loss_separation = self.separation_loss(feat_mean_stack)
            # total loss, opt.loss_weight: 0.1
            loss = loss_separation + 0.1 * loss_cohesion # opt.loss_weight
        elif self.use_CEloss == 0:
            render_mask = (render_mask.permute(0, 3, 1, 2)/2 + 0.5) * (self.num_classes-1)
            gt_mask =gt_mask.permute(0, 3, 1, 2)
            loss = 0.8 * l1_loss(render_mask, gt_mask) + 0.2 * (1.0 - ssim(render_mask, gt_mask))
        elif self.use_CEloss == 4: # æ— ç”¨ [-2 , 2] å¿˜è®°å…ˆå½’ä¸€åŒ–äº†
            render_mask = render_mask.permute(0, 3, 1, 2) * (self.num_classes-1)
            gt_mask =gt_mask.permute(0, 3, 1, 2)
            loss = 0.8 * l1_loss(render_mask, gt_mask) + 0.2 * (1.0 - ssim(render_mask, gt_mask))
        elif self.use_CEloss == 5: # ç”¨renderçš„language
            render_mask = render_mask.permute(0, 3, 1, 2) * (self.num_classes-1)
            gt_mask =gt_mask.permute(0, 3, 1, 2)
            loss = self._mask_ce_loss_fn(render_mask, gt_mask)

        return loss

    def _mask_ce_loss_fn(self, render_mask, gt_mask):
        """
        render_embed: [bs, h, w, 3]
        gt_embed: [bs, h, w, 3]
        """
        MIN_DENOMINATOR = 1e-12
        render_mask = (render_mask - render_mask.min()) / (render_mask.max() - render_mask.min() + MIN_DENOMINATOR)
        loss_mask = self.CrossEntropyLoss(render_mask, gt_mask)
        return loss_mask

    def _save_gradient(self, name):
        """
        ç”¨ä½œç¥žç»ç½‘ç»œä¸­çš„é’©å­ï¼Œä»¥ä¾¿åœ¨åå‘ä¼ æ’­æ—¶æ•èŽ·å’Œæ£€æŸ¥æ¢¯åº¦ã€‚
        é’©å­å‡½æ•°å¯ä»¥åœ¨æ¢¯åº¦è®¡ç®—å®ŒæˆåŽæ‰§è¡Œé¢å¤–çš„æ“ä½œï¼Œä¾‹å¦‚æ‰“å°ä¿¡æ¯æˆ–æ£€æŸ¥æ¢¯åº¦çš„å€¼ã€‚
        for debugging language feature rendering
        """
        def hook(grad):
            print(f"name={name}, grad={grad}")
            return grad
        return hook

    def extract_foundation_model_feature(self, gt_rgb, lang_goal):
        """
        ä»ŽåŸºç¡€æ¨¡åž‹ä¸­æå–ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯èƒ½ç”¨äºŽå›¾åƒæ¸²æŸ“ã€å›¾åƒå¤„ç†æˆ–å…¶ä»–æœºå™¨å­¦ä¹ ä»»åŠ¡
        we use the last layer of the diffusion feature extractor  æˆ‘ä»¬ä½¿ç”¨æ‰©æ•£ç‰¹å¾æå–å™¨çš„æœ€åŽä¸€å±‚
        å› ä¸ºæˆ‘ä»¬å°† 128x128 çš„å›¾åƒé‡å¡‘ä¸º 512x512ï¼Œæ‰€ä»¥æœ€åŽä¸€å±‚çš„ç‰¹å¾åªæ˜¯ 128x128
        since we reshape 128x128 img to 512x512, the last layer's feature is just 128x128
        thus, no need to resize the feature map    å› æ­¤ï¼Œæ— éœ€è°ƒæ•´ç‰¹å¾å›¾çš„å¤§å°
        lang_goal: numpy.ndarray, [bs, 1, 1]
        """
        
        if self.model_name == "diffusion":
            """
            we support multiple captions for batched input here
            """
            if lang_goal.shape[0] > 1:
                caption = ['a robot arm ' + cap.item() for cap in lang_goal]
            else:
                caption = "a robot arm " + lang_goal.item()
            batched_input = {'img': self.diffusion_preprocess(gt_rgb.permute(0, 3, 1, 2)), 'caption': caption}
            feature_list, lang_embed = self.feature_extractor(batched_input) # list of visual features, and 77x768 language embedding
            used_feature_idx = -1  
            gt_embed = feature_list[used_feature_idx]   # [bs,512,128,128]

            # NOTE: dimensionality reduction with PCA, which is used to satisfy the output dimension of the Gaussian Renderer
            bs = gt_rgb.shape[0]
            A = gt_embed.reshape(bs, 512, -1).permute(0, 2, 1)  # [bs, 128*128, 512]
            gt_embed_list = []
            for i in range(bs):
                U, S, V = torch.pca_lowrank(A[i], q=np.maximum(6, self.d_embed))
                reconstructed_embed = torch.matmul(A[i], V[:, :self.d_embed])
                gt_embed_list.append(reconstructed_embed)

            gt_embed = torch.stack(gt_embed_list, dim=0).permute(0, 2, 1).reshape(bs, self.d_embed, 128, 128)
            return gt_embed
        
        elif self.model_name == "dinov2":
            batched_input = self.dino_preprocess(gt_rgb.permute(0, 3, 1, 2))    # resize
            feature = self.feature_extractor(batched_input)
            gt_embed = F.interpolate(feature, size=(128, 128), mode='bilinear', align_corners=False)    # [b, 1024, 128, 128]

            # NOTE: dimensionality reduction with PCA, which is used to satisfy the output dimension of the Gaussian Renderer
            bs = gt_rgb.shape[0]
            A = gt_embed.reshape(bs, 1024, -1).permute(0, 2, 1)  # [bs, 128*128, 1024]
            gt_embed_list = []
            for i in range(bs):
                U, S, V = torch.pca_lowrank(A[i], q=np.maximum(6, self.d_embed))
                reconstructed_embed = torch.matmul(A[i], V[:, :self.d_embed])
                gt_embed_list.append(reconstructed_embed)
            gt_embed = torch.stack(gt_embed_list, dim=0).permute(0, 2, 1).reshape(bs, self.d_embed, 128, 128)
            return gt_embed
        else:
            return None

    def encode_data(self, pcd, dec_fts, lang, 
                    rgb=None, depth=None, mask=None, focal=None, c=None, lang_goal=None, tgt_pose=None, tgt_intrinsic=None,
                    next_tgt_pose=None, next_tgt_intrinsic=None, action=None, step=None, 
                    gt_mask_camera_extrinsic=None, gt_mask_camera_intrinsic=None, indx=None,
                    next_gt_mask_camera_extrinsic=None, next_gt_mask_camera_intrinsic=None,
                    gt_mask=None,next_gt_mask = None,
                    ): # åŽç»­åˆ æŽ‰çš„ä¸€è¡Œ
        '''prepare data dict'''
        bs = pcd.shape[0]
        data = {}
        # format input
        data['img'] = rgb
        # print("\033[0;31;40m rgb in neural_rendering.py\033[0m",rgb)
        data['dec_fts'] = dec_fts
        # print("encode_data ----- dec_fts.shape", dec_fts.shape)
        data['depth'] = depth
        # print("\033[0;31;40m depth in neural_rendering.py\033[0m",depth)
        data['lang'] = lang
        data['action'] = action
        # maniaction ä¸ç¡®å®šrlé‚£ä¸ªåœ¨å‰
        right_action, left_action = torch.split(action, split_size_or_sections=8, dim=1)
        # print("self.field_type=",self.field_type)
        # if self.cfg.method.field_type == 'bimanual_LF':
        data['right_action'] = right_action
        data['left_action'] = left_action
        """ # right_action, left_action = action.chunk(2, dim=2) # agentå†™æ³•
        # print("\033[0;31;40mactionr in neural_rendering.py\033[0m",right_action)
        # print("\033[0;31;40mactionl in neural_rendering.py\033[0m",left_action)
        # print("\033[0;31;40maction in neural_rendering.py\033[0m",action)
        # tensor([[ 
        #   1.8244e-01, -1.2036e-01,  7.7095e-01, 6.9350e-05,  1.0000e+00,  2.3808e-04, -1.1926e-03,  0.0000e+00, 
        #   2.8597e-01,  3.3652e-01,  7.7093e-01, -9.3490e-05, 1.0000e+00,  7.0034e-04, 1.0216e-03,  0.0000e+00]], device='cuda:0')
        # print(action.shape) # torch.Size([1, 16]) """
        data['step'] = step
        # if self.field_type == 'LF':

        if self.mask_gen == 'pre':
            data['mask_view'] = {}
            data['mask_view']['intr'] = gt_mask_camera_intrinsic # [indx] åœ¨renderï¼ˆï¼‰ä¸­ç¡®è®¤äº†
            data['mask_view']['extr'] = gt_mask_camera_extrinsic #  [indx]         
            if data['mask_view']['intr'] is not None:
                data_novel = self.get_novel_calib(data['mask_view'], True)
                data['mask_view'].update(data_novel) # æ›´æ–°æ•°æ®
        elif self.mask_gen == 'nonerf':
            data['mask'] = mask

        # novel pose
        data['novel_view'] = {}
        data['intr'] = tgt_intrinsic # nerf ç›¸æœºå†…å‚é€šå¸¸åŒ…æ‹¬ç„¦è·ã€ä¸»ç‚¹åæ ‡ç­‰ï¼Œç”¨äºŽå°†3Dåæ ‡è½¬æ¢ä¸º2Då›¾åƒåæ ‡ã€‚
        data['extr'] = tgt_pose     # ç›¸æœºå¤–å‚é€šå¸¸åŒ…æ‹¬æ—‹è½¬çŸ©é˜µå’Œå¹³ç§»å‘é‡ï¼Œç”¨äºŽå°†ä¸–ç•Œåæ ‡è½¬æ¢ä¸ºç›¸æœºåæ ‡ã€‚ç›¸æœºå¤–å‚å®šä¹‰äº†ç›¸æœºåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä½ç½®å’Œæ–¹å‘ã€‚
        data['xyz'] = einops.rearrange(pcd, 'b c h w -> b (h w) c') # bs,256*256,(xyz)
        #  einops.rearrange å‡½æ•°é‡æ–°æŽ’åˆ—ç‚¹äº‘æ•°æ® pcd   'b c h w -> b (h w) c' æ˜¯ä¸€ä¸ªé‡ç»„æ“ä½œçš„æ¨¡å¼ï¼Œå®ƒå°†è¾“å…¥å¼ é‡
        # ä»Žå››ç»´æ ¼å¼ï¼ˆå¯èƒ½è¡¨ç¤º [batch_size, channels, height, width]ï¼‰è½¬æ¢ä¸ºä¸‰ç»´æ ¼å¼ï¼Œ  å…¶ä¸­é«˜åº¦å’Œå®½åº¦è¢«åˆå¹¶ä¸ºä¸€ä¸ªç»´åº¦ã€‚è¿™é€šå¸¸ç”¨äºŽå°†3Dç‚¹äº‘æ•°æ®ä»Žå›¾åƒæ ¼å¼è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼Œ

        # use extrinsic pose to generate gaussain parameters
        # ä½¿ç”¨ extrinsic pose(å¤–éƒ¨å§¿æ€) ç”Ÿæˆ Gaussain å‚æ•°
        if data['intr'] is not None:
            data_novel = self.get_novel_calib(data, True)
            data['novel_view'].update(data_novel)

        if self.use_dynamic_field:
            if self.field_type =='bimanual':      # åŒè‡‚åŒæ—¶å·¥ä½œ
                data['next'] = {
                    'extr': next_tgt_pose,
                    'intr': next_tgt_intrinsic,
                    'novel_view': {},
                }
                if data['next']['intr'] is not None:
                    data_novel = self.get_novel_calib(data['next'], False)
                    data['next']['novel_view'].update(data_novel)
            elif self.field_type =='LF':                         # çœ‹åšleader followerå­¦ä¹   
                if self.mask_gen == 'pre':          # maskè‡ªå·±è®¡ç®—
                    data['right_next'] = {
                        'extr': next_tgt_pose,
                        'intr': next_tgt_intrinsic,
                        'novel_view': {},
                    }
                    if data['right_next']['intr'] is not None:
                        # ä¸ºäº†ç”Ÿæˆå·¦è‡‚çš„mask
                        data_novel = self.get_novel_calib(data['right_next'], False)
                        data['right_next']['novel_view'].update(data_novel)
                        # mask_viewç”¨æ¥è®­ç»ƒçš„maskå‚æ•°ï¼Œnovel_viewç”¨æ¥ç”Ÿæˆ åˆ†å‰²ç”¨çš„mask
                        data['right_next']['mask_view'] = {}
                        # test ä¸ºäº†maskè®­ç»ƒ
                        data['right_next']['mask_view']['intr'] = next_gt_mask_camera_intrinsic # [indx] 
                        data['right_next']['mask_view']['extr'] = next_gt_mask_camera_extrinsic # [indx]   
                        if data['right_next']['mask_view']['intr'] is not None:
                            data_novel_test = self.get_novel_calib(data['right_next']['mask_view'], True)
                            data['right_next']['mask_view'].update(data_novel_test) # æ›´æ–°æ•°æ®

                    data['left_next'] = {
                        'extr': next_tgt_pose,
                        'intr': next_tgt_intrinsic,
                        'novel_view': {},
                    }
                    if data['left_next']['intr'] is not None:
                        data_novel = self.get_novel_calib(data['left_next'], False)
                        data['left_next']['novel_view'].update(data_novel)
                        data['left_next']['mask_view'] = {}
                        # data['mask_view']['intr'] = gt_mask_camera_intrinsic 
                        # data['mask_view']['extr'] = gt_mask_camera_extrinsic         
                        # if data['mask_view']['intr'] is not None:
                        #     data_novel = self.get_novel_calib(data)
                        # data['left_next']['mask_view'].update(data_novel) # æ›´æ–°æ•°æ®
                        data['left_next']['mask_view']['intr'] = next_gt_mask_camera_intrinsic # [indx] 
                        data['left_next']['mask_view']['extr'] = next_gt_mask_camera_extrinsic # [indx]   
                        if data['left_next']['mask_view']['intr'] is not None:
                            # print("left_next intr is not none")
                            data_novel_test = self.get_novel_calib(data['left_next']['mask_view'], True)
                            data['left_next']['mask_view'].update(data_novel_test) # æ›´æ–°æ•°æ®
                elif self.mask_gen == 'gt':                       # gt mask
                    data['right_next'] = {
                        'extr': next_tgt_pose,
                        'intr': next_tgt_intrinsic,
                        'novel_view': {},
                    }
                    if data['right_next']['intr'] is not None:
                        data_novel = self.get_novel_calib(data['right_next'],False)
                        data['right_next']['novel_view'].update(data_novel)
                    data['left_next'] = {
                        'extr': next_tgt_pose,
                        'intr': next_tgt_intrinsic,
                        'novel_view': {},
                    }
                    if data['left_next']['intr'] is not None:
                        data_novel = self.get_novel_calib(data['left_next'], False)
                        data['left_next']['novel_view'].update(data_novel)
                    # print("encode next gt (æ— éœ€mask)")
                elif self.mask_gen == 'nonerf':          # ä½¿ç”¨6ä¸ªç›¸æœºçš„å‚æ•°
                    data['right_next'] = {
                        'extr': next_tgt_pose,
                        'intr': next_tgt_intrinsic,
                        'novel_view': {},
                    }
                    if data['right_next']['intr'] is not None:
                        # ä¸ºäº†ç”Ÿæˆå·¦è‡‚çš„mask
                        data_novel = self.get_novel_calib(data['right_next'], False)
                        data['right_next']['novel_view'].update(data_novel)
                        # mask_viewç”¨æ¥è®­ç»ƒçš„maskå‚æ•°ï¼Œnovel_viewç”¨æ¥ç”Ÿæˆ åˆ†å‰²ç”¨çš„mask
                        # å‡†å¤‡é€šè¿‡è¯¥å…‰æ …åŒ–ä»£ç å®žçŽ°
                        # data['right_next']['mask_view'] = {}
                        # data['right_next']['mask_view'].update(data_novel) # æ›´æ–°æ•°æ® 

                    data['left_next'] = {
                        'extr': next_tgt_pose,
                        'intr': next_tgt_intrinsic,
                        'novel_view': {},
                    }
                    if data['left_next']['intr'] is not None:
                        data_novel = self.get_novel_calib(data['left_next'], False)
                        data['left_next']['novel_view'].update(data_novel)
                        # data['left_next']['mask_view'] = {}
                        # # #æ”¹äº†å…‰æ …åŒ–ä»£ç render_mask å°±å¯ä»¥æ³¨é‡Š
                        # data['left_next']['mask_view'].update(data_novel) # æ›´æ–°æ•°æ®

        return data

    def get_novel_calib(self, data, mask=False):
        """
        True :mask          False: rgb
        get readable camera state for gaussian renderer from gt_pose
        ä»Ž gt_pose èŽ·å– Gaussian Renderer çš„å¯è¯»æ‘„åƒæœºçŠ¶æ€
        :param data: dict
        :param data['intr']: intrinsic matrix
        :param data['extr']: c2w matrix

        :return: dict
        """
        bs = data['intr'].shape[0]
        device = data['intr'].device
        fovx_list, fovy_list, world_view_transform_list, full_proj_transform_list, camera_center_list = [], [], [], [], []
        for i in range(bs):
            intr = data['intr'][i, ...].cpu().numpy()
            if mask: # maskå›¾ç‰‡éœ€è¦ç¼©æ”¾åˆ°128 128
                intr = intr / 2

            extr = data['extr'][i, ...].cpu().numpy()
            extr = np.linalg.inv(extr)  # the saved extrinsic is actually cam2world matrix, so turn it to world2cam matrix ä¿å­˜çš„extrinsicå®žé™…ä¸Šæ˜¯cam2worldçŸ©é˜µï¼Œæ‰€ä»¥å°†å…¶è½¬ä¸ºworld2camçŸ©é˜µ

            width, height = self.W, self.H
            R = np.array(extr[:3, :3], np.float32).reshape(3, 3).transpose(1, 0)    # inverse æ—‹è½¬çŸ©é˜µ
            T = np.array(extr[:3, 3], np.float32)                                   # ç§»åŠ¨
            FovX = focal2fov(intr[0, 0], width)     # è§†åœºè§’=focal2fovï¼ˆç„¦è·ï¼Œw) 
            FovY = focal2fov(intr[1, 1], height)
            projection_matrix = getProjectionMatrix(znear=self.znear, zfar=self.zfar, K=intr, h=height, w=width).transpose(0, 1)
            world_view_transform = torch.tensor(getWorld2View2(R, T, np.array(self.trans), self.scale)).transpose(0, 1) # [4, 4], w2c
            full_proj_transform = (world_view_transform.unsqueeze(0).bmm(projection_matrix.unsqueeze(0))).squeeze(0)    # [4, 4]
            camera_center = world_view_transform.inverse()[3, :3]   # inverse is c2w

            fovx_list.append(FovX)
            fovy_list.append(FovY)
            world_view_transform_list.append(world_view_transform.unsqueeze(0))
            full_proj_transform_list.append(full_proj_transform.unsqueeze(0))
            camera_center_list.append(camera_center.unsqueeze(0))

        novel_view_data = {
            'FovX': torch.FloatTensor(np.array(fovx_list)).to(device),
            'FovY': torch.FloatTensor(np.array(fovy_list)).to(device),
            'width': torch.tensor([width] * bs).to(device),
            'height': torch.tensor([height] * bs).to(device),
            'world_view_transform': torch.concat(world_view_transform_list).to(device),
            'full_proj_transform': torch.concat(full_proj_transform_list).to(device),
            'camera_center': torch.concat(camera_center_list).to(device),
        }

        return novel_view_data

    def forward(self, pcd, dec_fts, language, mask=None, gt_rgb=None, gt_pose=None, gt_intrinsic=None, rgb=None, depth=None, camera_intrinsics=None, camera_extrinsics=None, 
                focal=None, c=None, lang_goal=None, gt_depth=None,
                next_gt_pose=None, next_gt_intrinsic=None, next_gt_rgb=None, step=None, action=None,
                training=True, gt_mask=None, gt_mask_camera_extrinsic=None, gt_mask_camera_intrinsic=None, next_gt_mask = None,
                next_gt_mask_camera_extrinsic=None, next_gt_mask_camera_intrinsic=None,
                gt_maskdepth=None,next_gt_maskdepth=None,):
        '''
        main forward function
        Return:
        :loss_dict: dict, loss values
        :ret_dict: dict, rendered images
        '''
        bs = rgb.shape[0]
        # print("dec_fts.shape=",dec_fts.shape)
        # print("å¥½å§ï¼Œè¿™é‡Œçš„dataä¹Ÿæœ‰é—®é¢˜ï¼Œä½†æ˜¯è°å¹²çš„æ˜¯è°è°ƒç”¨äº†æˆ‘çš„neuralrender forwardå•Šå•Šå•Š!!!! bs=",bs)
        # æ•°æ®é¢„å¤„ç† return å­—å…¸å¯¹åº”å„ç±»ä¿¡æ¯
        indx = random.randint(0, 1) # 0 front or 1 overhead
        if self.mask_gen == 'nonerf':
            data = self.encode_data(
                rgb=rgb, depth=depth, pcd=pcd, focal=focal, c=c, lang_goal=None, tgt_pose=gt_pose, tgt_intrinsic=gt_intrinsic,
                dec_fts=dec_fts, lang=language, next_tgt_pose=next_gt_pose, next_tgt_intrinsic=next_gt_intrinsic, 
                action=action, step=step, gt_mask=gt_mask, gt_mask_camera_extrinsic=gt_mask_camera_extrinsic, gt_mask_camera_intrinsic=gt_mask_camera_intrinsic,  
                next_gt_mask=next_gt_mask, indx = indx, 
            )
        else:
            data = self.encode_data(
                rgb=rgb, depth=depth, pcd=pcd,mask=mask, focal=focal, c=c, lang_goal=None, 
                tgt_pose=gt_pose, tgt_intrinsic=gt_intrinsic,next_tgt_pose=next_gt_pose, next_tgt_intrinsic=next_gt_intrinsic,   # ç›¸æœºå‚æ•°
                dec_fts=dec_fts, lang=language, action=action, step=step, 
                gt_mask=gt_mask,next_gt_mask=next_gt_mask, 
                gt_mask_camera_extrinsic=gt_mask_camera_extrinsic, gt_mask_camera_intrinsic=gt_mask_camera_intrinsic, 
                next_gt_mask_camera_extrinsic=next_gt_mask_camera_extrinsic, next_gt_mask_camera_intrinsic=next_gt_mask_camera_intrinsic, 
                            )

        # æ¸²æŸ“ novelè§†è§’
        render_novel = None
        next_render_novel = None
        render_embed = None
        gt_embed = None
        render_mask_gtrgb = None
        render_mask_novel = None
        next_render_mask_right = None
        next_render_mask = None
        next_render_rgb_right = None
        next_left_mask_gen, exclude_left_mask = None, None
        gt_mask_vis,next_gt_mask_vis = None, None

        # create gt feature from foundation models ä»ŽåŸºç¡€æ¨¡åž‹åˆ›å»º gtç‰¹å¾
        # ç”¨äºŽæš‚æ—¶ç¦ç”¨PyTorchä¸­çš„æ¢¯åº¦è®¡ç®—
        with torch.no_grad():
            # æå–åŸºç¡€æ¨¡åž‹ç‰¹å¾ # Diffusion or dinov2
            gt_embed = self.extract_foundation_model_feature(gt_rgb, lang_goal)
        
        # change the mask
        if self.mask_gen == 'pre':
            
            # print("1 origin mask",gt_mask.shape)
            gt_mask = F.interpolate(gt_mask, size=(128, 128), mode='bilinear', align_corners=False)
            # print("2 mask",gt_mask.shape)
            gt_mask =gt_mask.permute(0,2,3,1) # [1, 1, 256, 256] ->[1, 256, 256, 1]
            if (self.use_CEloss >=1 and self.use_CEloss <= 3) or (self.use_CEloss == 7) or (self.use_CEloss == 21):
                gt_mask_label = self.mask_label_onehot(gt_mask) # 1 128 128 [target 0 1 2]  è¿™é‡Œä¸æ”¹ï¼Œç®—çš„æ—¶å€™-1å³å¯
                """ # test_onehot = self.mask_onehot(gt_mask) # [1 128 128 3]
                # device = gt_mask.device  # èŽ·å– next_gt_rgb çš„è®¾å¤‡ print("test.shape",test.shape,test)  
                # test_onehot = test_onehot.to(device).permute(0, 3, 1, 2)  # [1 128 128 3] -> [1 3 128 128]
                # loss_test = self._mask_loss_fn(test_onehot,gt_mask_label)   
                # print("loss_test = ",loss_test)
                # test_onehot = test_onehot.repeat(1, 1, 1, 3)
                    # gt_mask_label_test = self.mask_label_onehot(gt_mask)
                    # test_onehot1 = self.one_hot_encode(gt_mask_label_test,3)
                    # loss_test1 = self.CrossEntropyLoss(test_onehot1,gt_mask_label_test)  
                    # print("loss_test1 = ",loss_test1)         
                # print("L1gt_mask_label =[000 111 222]",gt_mask_label.shape, gt_mask_label) """
            elif self.use_CEloss == 0:
                # print("3 mask",gt_mask.shape)
                gt_mask_label = self.mask_label(gt_mask) # [1 128 128 3]   
            elif self.use_CEloss == 4:
                gt_mask_label = self.mask_label(gt_mask) 
                gt_mask = gt_mask_label
            elif self.use_CEloss == 5: # ç”¨renderçš„language
                gt_mask_label = self.mask_label(gt_mask)    # [1 128 128 1] -> [1 128 128 3] [000 / 111 / 222]
            # 6 only rgb
            if self.use_dynamic_field:
                next_gt_mask = F.interpolate(next_gt_mask, size=(128, 128), mode='bilinear', align_corners=False)
                next_gt_mask =next_gt_mask.permute(0,2,3,1) # [1, 1, 256, 256] ->[1, 256, 256, 1]
                if (self.use_CEloss >=1 and self.use_CEloss <= 3) or (self.use_CEloss == 7) or (self.use_CEloss == 21):
                    next_gt_mask_label = self.mask_label_onehot(next_gt_mask) # 1 128 128 [target 0 1 2]   7:è¿™é‡Œä¸æ”¹ï¼Œç®—lossæ—¶-1[-1,0,1]å³å¯
                elif self.use_CEloss == 0: #L1
                    next_gt_mask_label = self.mask_label(next_gt_mask) # [1 128 128 3]   
                elif self.use_CEloss == 4:
                    next_gt_mask_label = self.mask_label(next_gt_mask) 
                    next_gt_mask = next_gt_mask_label
                elif self.use_CEloss == 5: # ç”¨renderçš„language
                    next_gt_mask_label = self.mask_label(next_gt_mask)    # [1 128 128 1] -> [1 128 128 3] [000 / 111 / 222]

        # if gt_rgb is not None:
        if training:
            # Gaussian Generator é«˜æ–¯ç”Ÿæˆå™¨ gs regress (g) åº”è¯¥ä¹Ÿä¸ç”¨æ”¹
            data = self.gs_model(data) # GeneralizableGSEmbedNet(cfg, with_gs_render=True)

            # Gaussian Render
            data = self.pts2render(data, bg_color=self.bg_color) # default: [0, 0, 0]

            # Loss L(GEO) å½“å‰åœºæ™¯ä¸€è‡´æ€§æŸå¤± Current Scence Consistency Loss
            # permuteç½®æ¢  å°†å¼ é‡çš„ç»´åº¦ä»ŽåŽŸæ¥çš„é¡ºåºé‡æ–°æŽ’åˆ—ä¸ºæ–°çš„é¡ºåº 
            render_novel = data['novel_view']['img_pred'].permute(0, 2, 3, 1)   # [1, 128, 128, 3]            

            # visdom è§†ç•Œ(å¯è§†åŒ–æ•°æ®ç”¨çš„) Manigaussian2 ä¸­æ˜¯False bashä¸­å¥½åƒä¹Ÿæ²¡æœ‰æŒ‡å®š
            if self.cfg.visdom: # False
                vis = visdom.Visdom()
                rgb_vis = data['img'][0].detach().cpu().numpy() * 0.5 + 0.5
                vis.image(rgb_vis, win='front_rgb', opts=dict(title='front_rgb'))

                depth_vis = data['depth'][0].detach().cpu().numpy()#/255.0
                # convert 128x128 0-255 depth map to 3x128x128 0-1 colored map 
                # å°† 128x128 0-255 æ·±åº¦è´´å›¾è½¬æ¢ä¸º 3x128x128 0-1 å½©è‰²è´´å›¾
                vis.image(depth_vis, win='front_depth', opts=dict(title='front_depth'))
                vis.image(render_novel[0].permute(2, 0, 1).detach().cpu().numpy(), win='render_novel', opts=dict(title='render_novel'))
                vis.image(gt_rgb[0].permute(2, 0, 1).detach().cpu().numpy(), win='gt_novel', opts=dict(title='gt_novel'))
            
            loss = 0.
            Ll1 = l2_loss(render_novel, gt_rgb) # loss_now_rgb
            # Lssim = 1.0 - ssim(render_novel, gt_rgb)
            Lssim = 0.
            # PSNRå¥½åƒè¡¨ç¤ºå›¾ç‰‡è´¨é‡ï¼Ÿ
            psnr = PSNR_torch(render_novel, gt_rgb)

            # loss_rgb = self.cfg.lambda_l1 * Ll1 + self.cfg.lambda_ssim * Lssim
            loss_rgb = Ll1
            # 1 LGeo?
            loss += loss_rgb

            # è¯­ä¹‰ï¼ˆoptionalï¼‰
            if gt_embed is not None:
                # æ¯”è¾ƒçœŸå®žå’Œrenderçš„embed åº”è¯¥æ˜¯è¯­ä¹‰Lsem
                gt_embed = gt_embed.permute(0, 2, 3, 1) # channel last
                render_embed = data['novel_view']['embed_pred'].permute(0, 2, 3, 1)

                # DEBUG gradient    debug æ¢¯åº¦
                # render_embed_grad = render_embed.register_hook(self._save_gradient('render_embed'))

                loss_embed = self._embed_loss_fn(render_embed, gt_embed)
                # 2 loss(LGeo? + embedæ˜¯å•¥ åº”è¯¥æ˜¯è¯­ä¹‰Lsem) = loss_rgb + self.cfg.lambda_embed * loss_embed
                loss += self.cfg.lambda_embed * loss_embed
            else:
                loss_embed = torch.tensor(0.)

            # Ll1 = l1_loss(render_novel, gt_rgb) 
            loss_dyna_mask = torch.tensor(0.) 
            if self.mask_gen == 'nonerf':
                gt_rgb = gt_rgb.permute(0,2,3,1) # [1, 3, 256, 256] ->[1, 256, 256, 3]
                gt_mask =gt_mask.permute(0,2,3,1) # [1, 1, 256, 256] ->[1, 256, 256, 1]
                # gt_mask_label = self.mask_label(gt_mask) # 100 010  001
                # # print("gt_mask_label = ",gt_mask_label.shape,gt_mask_label)
                # # 1 å½“å‰åœºæ™¯çš„mask è®­ç»ƒ  loss_dyna_mask_novel
                # data =self.pts2render_mask_gen(data, bg_color=self.bg_mask)
                # render_mask_novel = data['novel_view']['mask_gen'] # .permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]                           
                # loss_dyna_mask_novel = self.CrossEntropyLoss(render_mask_novel, gt_mask_label) # maskçŽ°é˜¶æ®µçš„
                # render_mask_novel = render_mask_novel.permute(0, 2, 3, 1)
                # loss_dyna_mask = loss_dyna_mask_novel
                # lambda_mask = 0 # 1  if step >= 40000 else 0
                # loss += loss_dyna_mask * lambda_mask # * 0.001
                
                # print("render_novel.shape",render_novel.shape)
                # print("gt_rgb.shape",gt_rgb.shape)
                if self.use_dynamic_field:
                    next_gt_rgb = next_gt_rgb.permute(0,2,3,1)
                    next_gt_mask = next_gt_mask.permute(0,2,3,1)
            elif self.mask_gen == 'pre':
                # 1 å½“å‰åœºæ™¯çš„mask è®­ç»ƒ  loss_dyna_mask_novel
                data =self.pts2render_mask(data, bg_color=self.bg_mask)
                # print("1 gt_mask_label = ",gt_mask_label.shape, gt_mask_label)              # [1 128 128]
                # print("2 render_mask_novel = ",render_mask_novel.shape, render_mask_novel)  # [1 3 128 128]
                if self.use_CEloss==1 or self.use_CEloss == 7 or self.use_CEloss == 21:
                    render_mask_novel = data['novel_view']['mask_pred'] # 1 3 128 128 
                    loss_dyna_mask_novel = self._mask_loss_fn(render_mask_novel, gt_mask_label) #gt_mask) # maskçŽ°é˜¶æ®µçš„ _mask_loss_fn
                    render_mask_novel = render_mask_novel.permute(0, 2, 3, 1)
                    # # print("render_mask_novel = ",render_mask_novel.shape)
                    # # next_render_mask_right = self.vis_labels(render_mask_novel) # debug çš„æ—¶å€™ç”¨ä¸€ä¸‹
                    # # render_mask_novel = self.generate_final_class_labels(render_mask_novel)      
                elif self.use_CEloss==2:
                    render_mask_novel = data['novel_view']['mask_pred'] # 1 3 128 128 
                    render_mask_novel = render_mask_novel[:, [0, 1], :, :]
                    loss_dyna_mask_novel = self._mask_loss_fn(render_mask_novel, gt_mask_label) #gt_mask) # maskçŽ°é˜¶æ®µçš„ _mask_loss_fn
                    render_mask_novel = render_mask_novel.permute(0, 2, 3, 1)
                elif self.use_CEloss == 0:
                    render_mask_novel = data['novel_view']['mask_pred'].permute(0, 2, 3, 1)
                    loss_dyna_mask_novel = self._mask_loss_fn(render_mask_novel, gt_mask_label)  # gt_mask) # maskçŽ°é˜¶æ®µçš„ _mask_loss_fn
                # loss_dyna_mask_novel = self._mask_loss_fn(render_mask_novel, gt_mask_label)  # gt_mask) # maskçŽ°é˜¶æ®µçš„ _mask_loss_fn
                # print("loss_dyna_mask_novel = ",loss_dyna_mask_novel)    
                elif self.use_CEloss == 3:   # open
                    render_mask_novel = data['novel_view']['mask_pred'] # 1 3 128 128 
                    one_hot = F.one_hot(gt_mask_label.type(torch.int64), num_classes=3) #int(instance_num.item() + 1))
                    gt_mask_label = one_hot.permute(0,3, 1, 2)
                    loss_dyna_mask_novel = self._mask_loss_fn(render_mask_novel, gt_mask_label) #gt_mask) # maskçŽ°é˜¶æ®µçš„ _mask_loss_fn
                    render_mask_novel = render_mask_novel.permute(0, 2, 3, 1)    
                elif self.use_CEloss == 4:
                    # data =self.pts2render_mask(data, bg_color=self.bg_mask)
                    # render_novel = data['novel_view']['mask_pred'].permute(0, 2, 3, 1)
                    render_mask_novel = data['novel_view']['mask_pred'].permute(0, 2, 3, 1) # 1 3 128 128 
                    loss_dyna_mask_novel = self._mask_loss_fn(render_mask_novel, gt_mask_label) #gt_mask) # maskçŽ°é˜¶æ®µçš„ _mask_loss_fn
                    render_mask_novel = render_mask_novel.permute(0, 2, 3, 1)                    
                elif self.use_CEloss == 5:
                    data =self.pts2render1(data, bg_color=self.bg_color)
                    render_mask_novel = data['novel_view']['embed_pred'].permute(0, 2, 3, 1) 
                    loss_dyna_mask_novel = self._mask_loss_fn(render_mask_novel, gt_mask_label)  
       

                if not self.use_dynamic_field and self.use_CEloss != 6:
                    loss_dyna_mask = loss_dyna_mask_novel
                    lambda_mask =1   if step >= 1000 else 0
                    loss += loss_dyna_mask * lambda_mask # * 0.001
                elif self.use_CEloss != 6:
                    # loss_dyna_mask = loss_dyna_mask_novel * (1 - self.cfg.lambda_next_loss_mask)
                    lambda_mask = self.cfg.lambda_mask if step >= self.cfg.mask_warm_up else 0. # 0.4 2000
                    loss += loss_dyna_mask_novel * lambda_mask # * 0.001


            # next frame prediction ä¸‹ä¸€å¸§é¢„æµ‹ Ldyna(optional)
            if self.field_type == 'bimanual':
                if self.use_dynamic_field and (next_gt_rgb is not None) and ('xyz_maps' in data['next']):
                    data['next'] = self.pts2render(data['next'], bg_color=self.bg_color)
                    next_render_novel = data['next']['novel_view']['img_pred'].permute(0, 2, 3, 1)
                    loss_dyna = l2_loss(next_render_novel, next_gt_rgb)
                    lambda_dyna = self.cfg.lambda_dyna if step >= self.cfg.next_mlp.warm_up else 0.
                    loss += lambda_dyna * loss_dyna

                    loss_reg = torch.tensor(0.)
                    # TODO: regularization on deformation 
                    # è€ƒè™‘åŠ å…¥ä¸€äº›æ­£åˆ™åŒ–é¡¹æ¥å¤„ç†å½¢å˜ï¼ˆdeformationï¼‰
                    # if self.cfg.lambda_reg > 0:
                    #     loss_reg = l2_loss(data['next']['xyz_maps'], data['xyz_maps'].detach()) #detachä¸è¿½è¸ªæ¢¯åº¦çš„å¼ é‡ï¼Ÿ
                    #     lambda_reg = self.cfg.lambda_reg if step >= self.cfg.next_mlp.warm_up else 0.
                    #     loss += lambda_reg * loss_reg

                    # TODO: local rigid loss å±€éƒ¨åˆšæ€§æŸå¤±
                    loss_LF = torch.tensor(0.)
                    loss_dyna_mask = torch.tensor(0.)
                else:
                    loss_dyna = torch.tensor(0.)
                    loss_LF = torch.tensor(0.)
                    loss_dyna_mask = torch.tensor(0.)
                    loss_reg = torch.tensor(0.)
            elif self.field_type == 'LF':    # Leader Follower condition
                if self.mask_gen == 'gt':   # maskçŽ°æˆçš„gt
                    if self.use_dynamic_field and next_gt_rgb is not None:
                        # å·¦æ‰‹çš„ç‚¹äº‘
                        # time1 = time.perf_counter()
                        # time_step1 = time2 - time1
                        # print(f"1 ### time1 = {time1}")   
                        mask_3d, next_mask_3d = self.createby_gt_mask(data=data, gt_mask=gt_mask, 
                            gt_mask_camera_extrinsic=gt_mask_camera_extrinsic, gt_mask_camera_intrinsic=gt_mask_camera_intrinsic,  
                            next_gt_mask=next_gt_mask,gt_maskdepth=gt_maskdepth, next_gt_maskdepth=next_gt_maskdepth)
                        # time2 = time.perf_counter()
                        # time_step1 = time2 - time1
                        # print(f"2 ### time3 = {time2} step1 = {time_step1:.2f}s å‡¸åŒ…") # 0.82s -> 0.6 (è®¡ç®—3dç‚¹æ”¹ç”¨torchæ–¹æ³•)

                        # æŠ•å½±åˆ°äºŒç»´ (äºŒç»´ç‚¹)
                        projected_points = project_3d_to_2d(next_mask_3d, next_gt_intrinsic)
                        
                        # time3 = time.perf_counter()
                        # time_step2 = time3 - time2
                        # print(f"3 ### time3 = {time3} step1 = {time_step2:.2f}s å‡¸åŒ…->2D") # 1.05/1.57s      

                        # åˆ›å»ºäºŒç»´æŽ©ç  ï¼ˆäºŒç»´çš„å‡¸åŒ…ï¼‰ å…¶å®žå¯ä»¥ä¸ç”¨è®¡ç®—ï¼Ÿ
                        # mask_shape = (256, 256)  # å‡è®¾çš„æŽ©ç å¤§å° ç”¨256,256æ›´åˆé€‚ ç„¶åŽå†ç¼©å°
                        mask_shape = (128, 128)
                        exclude_left_mask = create_2d_mask_from_convex_hull(projected_points, mask_shape)
                        exclude_left_mask = exclude_left_mask.unsqueeze(0).unsqueeze(-1).repeat(1, 1, 1, 3) # [1,256,256,3]
                        # exclude_left_mask = exclude_left_mask.permute(0, 3, 1, 2) # [1,3,256,256]
                        # exclude_left_mask = F.interpolate(exclude_left_mask, size=(128, 128), mode='bilinear', align_corners=False)
                        # exclude_left_mask = exclude_left_mask.permute(0, 2, 3, 1) # [1,128,128,3]

                        # time4 = time.perf_counter()
                        # time_step3 = time4 - time3
                        # print(f"4 ### time4 = {time4} step3 = {time_step3:.2f}s 2D->2D mask(æ±‚å‡¸åŒ…)")   

                        # print(f"exclude_left_mask.shape = {exclude_left_mask.shape}\n {exclude_left_mask}") # [1,256,256,3]
                        device = next_gt_rgb.device  # èŽ·å– next_gt_rgb çš„è®¾å¤‡
                        # ç¡®ä¿ exclude_left_mask åœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Š
                        exclude_left_mask = exclude_left_mask.to(device)
                        next_render_mask = exclude_left_mask
                        result_right_image = next_gt_rgb * exclude_left_mask
                        # print(f"next_gt_rgb = {next_gt_rgb.shape} {next_gt_rgb}") # [1,256,256,3]
                        render_mask_novel = result_right_image # çœ‹çœ‹èƒ½ä¸èƒ½å¯è§†åŒ–
                        # print(f"render_mask_novel.shape = {render_mask_novel.shape}\n {render_mask_novel}") # [1,256,256,3]
                        # time5 = time.perf_counter()
                        # time_step4 = time5 - time4
                        # print(f"5 ### time5 = {time5} step4 = {time_step4:.2f}s åŒ¹é…æ ¼å¼")                             

                        # 2 GRB total(Follower)  å…ˆå¯¹lefté¢„æµ‹ï¼ˆæœ€åŽçš„ç»“æžœï¼‰ loss_dyna_follower  å·¦è‡‚ RGB Loss   
                        # ä¹Ÿå¯ä»¥è¯´æ˜¯åŒæ‰‹ç»“æžœ
                        if ('xyz_maps' in data['left_next']):
                            data['left_next'] = self.pts2render(data['left_next'], bg_color=self.bg_color)
                            next_render_novel = data['left_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]
                            # print("4 next_gt_mask.shape = ",next_gt_mask.shape, next_render_novel.shape) # torch.Size([1, 128, 128, 3]) 
                            loss_dyna_follower = l2_loss(next_render_novel, next_gt_rgb) # åŒè‡‚ç»“æžœé¢„æµ‹
                        
                        #  4 RGB loss_dyna_leader leader  åˆ©ç”¨å‰é¢å¾—åˆ°çš„maskåˆ åŽ»å·¦è‡‚
                        if ('xyz_maps' in data['right_next']):
                            # with torch.no_grad():  åŽŸæ¥ä¸ºäº†æœ‰çš„Lossæ²¡è®¡ç®—æŠ¥æ— å›žä¼ é”™è¯¯è€Œå†™çš„
                            data['right_next'] = self.pts2render(data['right_next'], bg_color=self.bg_color)
                            next_render_rgb_right = data['right_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,128, 128, 3]
                            next_render_novel_mask = next_render_rgb_right * exclude_left_mask  # åŽŸæ¥ç”¨é”™äº†...  next_gt_rgb -> next_render_rgb_right
                            loss_dyna_leader = l2_loss(next_render_novel_mask, result_right_image)
                            # print('loss_dyna_leader = ', loss_dyna_leader)

                        # RGB pre = leader( right ) + follower
                        loss_LF = loss_dyna_leader * self.cfg.lambda_dyna_leader + loss_dyna_follower * (1-self.cfg.lambda_dyna_leader)

                        loss_dyna_mask = torch.tensor(0.) # ä¸ºäº†åœ¨é‚£é‡Œè¾“å‡º
                        loss_reg = torch.tensor(0.) 
                        loss_dyna = loss_LF    # * (1-self.cfg.lambda_mask) + loss_dyna_mask * self.cfg.lambda_mask 
                        # print('loss_dyna = ', loss_dyna,loss_LF,loss_dyna_mask)
                        # é¢„çƒ­æ­¥æ•°ï¼ˆ3000æ­¥ä»¥åŽç®—ä¸Šäº†ï¼‰
                        lambda_dyna = self.cfg.lambda_dyna if step >= self.cfg.next_mlp.warm_up else 0.                    
                        
                        # Step 3 Loss(LGeo? + L embed/L sem + L dyna) = loss_rgb + self.cfg.lambda_embed * loss_embed + lambda_dyna * loss_dyna
                        loss += lambda_dyna * loss_dyna
                    else:
                        loss_dyna = torch.tensor(0.)
                        loss_reg = torch.tensor(0.)      
                        loss_LF = torch.tensor(0.)
                        loss_dyna_mask = torch.tensor(0.)
                elif self.mask_gen == 'pre':   # éœ€è¦è‡ªå·±è®­ç»ƒmask  lossè¿˜æœ‰é—®é¢˜ï¼ˆmask å’Œmask labelï¼‰
                    if self.use_dynamic_field and (next_gt_rgb is not None and gt_mask is not None):
                        # 2 GRB total(Follower)  å…ˆå¯¹lefté¢„æµ‹ï¼ˆæœ€åŽçš„ç»“æžœï¼‰ loss_dyna_follower  å·¦è‡‚ RGB Loss   
                        if ('xyz_maps' in data['left_next']):
                            data['left_next'] = self.pts2render(data['left_next'], bg_color=self.bg_color)
                            next_render_novel = data['left_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]
                            # print("4 next_gt_mask.shape = ",next_gt_mask.shape, next_render_novel.shape) # torch.Size([1, 128, 128, 3]) 
                            loss_dyna_follower = l2_loss(next_render_novel, next_gt_rgb) # åŒè‡‚ç»“æžœé¢„æµ‹

                        # -------------------------------------------------------------------------------------------------------------------
                        # 3 next mask train (pre - left(mask) ) next_loss_dyna_mask_left  å·¦è‡‚ Mask Loss
                        # data['left_next'] =self.pts2render_mask(data['left_next'], bg_color=self.bg_mask)
                        # next_render_mask = data['left_next']['novel_view']['mask_pred'] # .permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]
                        # next_loss_dyna_mask_left = self.CrossEntropyLoss(next_render_mask, next_gt_mask_label) # maskåŽ»å·¦è‡‚çš„mask
                        # loss_dyna_mask_novel = self._mask_loss_fn(render_mask_novel, gt_mask_label)
                        # # next_render_mask = next_render_mask.permute(0, 2, 3, 1)

                        data['left_next'] =self.pts2render_mask(data['left_next'], bg_color=self.bg_mask)
                        data['left_next'] =self.pts2render_mask_gen(data['left_next'], bg_color=self.bg_mask)
                        if self.use_CEloss==1 or self.use_CEloss == 7 or self.use_CEloss == 21:
                            next_render_mask = data['left_next']['novel_view']['mask_pred'] # 1 3 128 128 
                            next_loss_dyna_mask_left = self._mask_loss_fn(next_render_mask, next_gt_mask_label) #gt_mask) # maskçŽ°é˜¶æ®µçš„ _mask_loss_fn
                            next_render_mask = next_render_mask.permute(0, 2, 3, 1) 
                            # gen exclude
                            next_left_mask_gen = data['left_next']['novel_view']['mask_gen'].permute(0, 2, 3, 1)  # 1 128 128 3   
                            exclude_left_mask = self.generate_final_class_labels(next_left_mask_gen)
                            exclude_left_mask = exclude_left_mask.unsqueeze(3).repeat(1, 1, 1, 3)
                        elif self.use_CEloss == 0:     # Ll1
                            next_render_mask = data['left_next']['novel_view']['mask_pred'].permute(0, 2, 3, 1) # 1 128 128 3(rgb label mean-> 0 1 2)
                            next_loss_dyna_mask_left = self._mask_loss_fn(next_render_mask, next_gt_mask_label) 

                            next_left_mask_gen = data['left_next']['novel_view']['mask_gen'].permute(0, 2, 3, 1) # 1 128 128 3
                            next_left_mask_gen = (next_left_mask_gen / 2 + 0.5  )*(self.num_classes-1)           # 1 128 128 3 [0,2]
                            exclude_left_mask = self.generate_final_class_labels_L1(next_left_mask_gen)

                        elif self.use_CEloss == 3:     # OpenGaussian ï¼Ÿ 2 3 è¦ä¸è¦åŠ æ³¨é‡Šï¼Ÿ
                            next_render_mask = data['left_next']['novel_view']['mask_pred'] # 1 3 128 128 
                            one_hot = F.one_hot(next_gt_mask_label.type(torch.int64), num_classes=3) #int(instance_num.item() + 1)) # å¯ä»¥æ”¹åˆ°å‰é¢åŽ»
                            next_gt_mask_label = one_hot.permute(0, 3, 1, 2)
                            next_loss_dyna_mask_left = self._mask_loss_fn(next_render_mask, next_gt_mask_label) #gt_mask) # maskçŽ°é˜¶æ®µçš„ _mask_loss_fn
                            next_render_mask = next_render_mask.permute(0, 2, 3, 1)  # 1 128 128 3  

                        elif self.use_CEloss == 4: # æ— ç”¨ å¿˜äº†å½’ä¸€åŒ–çš„L1
                            next_render_mask = data['novel_view']['mask_pred'].permute(0, 2, 3, 1) # 1 3 128 128 
                            next_loss_dyna_mask_left = self._mask_loss_fn(next_render_mask, next_gt_mask_label) 
                            next_render_mask = next_render_mask.permute(0, 2, 3, 1)                    
                        elif self.use_CEloss == 5:  # æ— ç”¨ æŠŠmaskä½œä¸ºlanguageç®—
                            data =self.pts2render1(data, bg_color=self.bg_color)
                            next_render_mask = data['novel_view']['embed_pred'].permute(0, 2, 3, 1) 
                            next_loss_dyna_mask_left = self._mask_loss_fn(next_render_mask, next_gt_mask_label)          
                        elif self.use_CEloss==2: # æ— ç”¨ ignore -1 [10 01] target: -1 0 1
                            next_render_mask = data['novel_view']['mask_pred'] # 1 3 128 128 
                            next_render_mask = next_render_mask[:, [0, 1], :, :]
                            next_loss_dyna_mask_left = self._mask_loss_fn(next_render_mask, next_gt_mask_label)
                            next_render_mask = next_render_mask.permute(0, 2, 3, 1)
                        # -------------------------------------------------------------------------------------------------------------------

                        # gen mask and exclude æ”¹åˆ°å‰é¢çš„ifä¸­äº†
                            # data['left_next'] =self.pts2render_mask_gen(data['left_next'], bg_color=self.bg_mask)
                            # next_left_mask_gen = data['left_next']['novel_view']['mask_gen'].permute(0, 2, 3, 1)                        
                            # # exclude_left_mask = (next_render_mask < left_min) | (next_render_mask > left_max) # æŽ’é™¤å·¦è‡‚æ ‡ç­¾ [1,128, 128, 3] [True,False]
                            # # exclude_left_mask = (next_left_mask_gen > 2.5) | (next_left_mask_gen < 1.5)
                            # exclude_left_mask = self.generate_final_class_labels(next_left_mask_gen)
                            # exclude_left_mask = exclude_left_mask.unsqueeze(3).repeat(1, 1, 1, 3)
                            # # background_color = torch.tensor(self.bg_color, dtype=torch.float32)  # èƒŒæ™¯
                        result_right_image = next_gt_rgb * exclude_left_mask # + background_color * (~exclude_left_mask) # [1, 128, 128, 3] #

                        #  4 RGB loss_dyna_leader leader  åˆ©ç”¨å‰é¢å¾—åˆ°çš„maskåˆ åŽ»å·¦è‡‚
                        if ('xyz_maps' in data['right_next']):
                            data['right_next'] = self.pts2render(data['right_next'], bg_color=self.bg_color)
                            next_render_rgb_right = data['right_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,128, 128, 3]
                            next_render_novel_mask = next_render_rgb_right * exclude_left_mask  # åŽŸæ¥ç”¨é”™äº†...  next_gt_rgb -> next_render_rgb_right
                            loss_dyna_leader = l2_loss(next_render_novel_mask, result_right_image)
                        

                        # -------------------------------------------------------------------------------------------------------------------
                        # 5 Mask loss_dyna_mask_next_right å³è‡‚maskè®­ç»ƒï¼ˆå’Œnowä¸€æ · æ— ç”¨ï¼‰
                            # data['right_next'] =self.pts2render_mask(data['right_next'], bg_color=self.bg_mask)
                            # next_render_mask_right = data['right_next']['novel_view']['mask_pred'].permute(0, 2, 3, 1)
                            # # next_loss_dyna_mask_right = self.CrossEntropyLoss(next_render_mask_right, next_gt_mask_label) #next_gt_mask)
                            # next_loss_dyna_mask_right = self._mask_loss_fn(next_render_mask_right, next_gt_mask_label)
                            # # next_render_mask_right = next_render_mask_right.permute(0, 2, 3, 1)

                        data['right_next'] =self.pts2render_mask(data['right_next'], bg_color=self.bg_mask)
                        if self.use_CEloss==1 or self.use_CEloss == 7 or self.use_CEloss == 21:
                            next_render_mask_right = data['right_next']['novel_view']['mask_pred'] # 1 3 128 128 
                            next_loss_dyna_mask_right = self._mask_loss_fn(next_render_mask_right, next_gt_mask_label) #gt_mask) # maskçŽ°é˜¶æ®µçš„ _mask_loss_fn
                            next_render_mask_right = next_render_mask_right.permute(0, 2, 3, 1) 
                        elif self.use_CEloss == 0:     # Ll1
                            next_render_mask_right = data['right_next']['novel_view']['mask_pred'].permute(0, 2, 3, 1) # 1 128 128 3(rgb label mean-> 0 1 2)
                            next_loss_dyna_mask_right = self._mask_loss_fn(next_render_mask_right, next_gt_mask_label) 

                        elif self.use_CEloss == 3:     # OpenGaussian ï¼Ÿ 2 3 è¦ä¸è¦åŠ æ³¨é‡Šï¼Ÿ
                            next_render_mask = data['right_next']['novel_view']['mask_pred'] # 1 3 128 128 
                            one_hot = F.one_hot(next_gt_mask_label.type(torch.int64), num_classes=3) #int(instance_num.item() + 1)) # å¯ä»¥æ”¹åˆ°å‰é¢åŽ»
                            next_gt_mask_label = one_hot.permute(0, 3, 1, 2)
                            next_loss_dyna_mask_left = self._mask_loss_fn(next_render_mask, next_gt_mask_label) #gt_mask) # maskçŽ°é˜¶æ®µçš„ _mask_loss_fn
                            next_render_mask = next_render_mask.permute(0, 2, 3, 1)  # 1 128 128 3  

                        elif self.use_CEloss == 4: # æ— ç”¨ å¿˜äº†å½’ä¸€åŒ–çš„L1
                            next_render_mask = data['novel_view']['mask_pred'].permute(0, 2, 3, 1) # 1 3 128 128 
                            next_loss_dyna_mask_left = self._mask_loss_fn(next_render_mask, next_gt_mask_label) 
                            next_render_mask = next_render_mask.permute(0, 2, 3, 1)                    
                        elif self.use_CEloss == 5:  # æ— ç”¨ æŠŠmaskä½œä¸ºlanguageç®—
                            data =self.pts2render1(data, bg_color=self.bg_color)
                            next_render_mask = data['novel_view']['embed_pred'].permute(0, 2, 3, 1) 
                            next_loss_dyna_mask_left = self._mask_loss_fn(next_render_mask, next_gt_mask_label)          
                        elif self.use_CEloss==2: # æ— ç”¨ ignore -1 [10 01] target: -1 0 1
                            next_render_mask = data['novel_view']['mask_pred'] # 1 3 128 128 
                            next_render_mask = next_render_mask[:, [0, 1], :, :]
                            next_loss_dyna_mask_left = self._mask_loss_fn(next_render_mask, next_gt_mask_label)
                            next_render_mask = next_render_mask.permute(0, 2, 3, 1)
                        # -------------------------------------------------------------------------------------------------------------------

                        # next mask = right +left    
                        next_loss_dyna_mask = next_loss_dyna_mask_left * ( 1 - self.cfg.lambda_mask_right ) + next_loss_dyna_mask_right * self.cfg.lambda_mask_right  # å³è‡‚æƒé‡å°ä¸€ç‚¹
                        
                        # MASK = now +pre
                        # loss_dyna_mask = loss_dyna_mask_novel * (1 - self.cfg.lambda_next_loss_mask)  + next_loss_dyna_mask * self.cfg.lambda_next_loss_mask
                        # loss_dyna_mask += next_loss_dyna_mask * self.cfg.lambda_next_loss_mask
                        loss_dyna_mask = next_loss_dyna_mask


                        # RGB pre = leader( right ) + follower
                        loss_LF = loss_dyna_leader * self.cfg.lambda_dyna_leader + loss_dyna_follower * (1-self.cfg.lambda_dyna_leader)
                        # print('loss_LF = ', loss_LF, loss_dyna_leader, loss_dyna_follower)

                        lambda_mask = self.cfg.lambda_mask if step >= self.cfg.next_mlp.warm_up + self.cfg.mask_warm_up else 0. # 5000
                        loss_dyna = loss_LF * (1 - lambda_mask) + loss_dyna_mask * lambda_mask

                        # print('loss_dyna = ', loss_dyna,loss_LF,loss_dyna_mask)
                        # é¢„çƒ­æ­¥æ•°ï¼ˆ3000æ­¥ä»¥åŽç®—ä¸Šäº†ï¼‰
                        lambda_dyna = self.cfg.lambda_dyna if step >= self.cfg.next_mlp.warm_up else 0.                    
                        
                        # Step 3 Loss(LGeo? + L embed/L sem + L dyna) = loss_rgb + self.cfg.lambda_embed * loss_embed + lambda_dyna * loss_dyna
                        loss += lambda_dyna * loss_dyna

                        loss_reg = torch.tensor(0.)
                    else:
                        loss_dyna = torch.tensor(0.)
                        loss_reg = torch.tensor(0.)      
                        loss_LF = torch.tensor(0.)
                        # loss_dyna_mask = torch.tensor(0.) 

                elif self.mask_gen == 'None':
                    if self.use_dynamic_field and (next_gt_rgb is not None):
                        # 2 GRB total(Follower)  å…ˆå¯¹lefté¢„æµ‹ï¼ˆæœ€åŽçš„ç»“æžœï¼‰ loss_dyna_follower  å·¦è‡‚ RGB Loss   
                        # ä¹Ÿå¯ä»¥è¯´æ˜¯åŒæ‰‹ç»“æžœ
                        if ('xyz_maps' in data['left_next']):
                            data['left_next'] = self.pts2render(data['left_next'], bg_color=self.bg_color)
                            next_render_novel = data['left_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]
                            loss_dyna_follower = l2_loss(next_render_novel, next_gt_rgb) # åŒè‡‚ç»“æžœé¢„æµ‹

                        #  4 RGB loss_dyna_leader leader  åˆ©ç”¨å‰é¢å¾—åˆ°çš„maskåˆ åŽ»å·¦è‡‚
                        if ('xyz_maps' in data['right_next']):
                            # with torch.no_grad():  åŽŸæ¥ä¸ºäº†æœ‰çš„Lossæ²¡è®¡ç®—æŠ¥æ— å›žä¼ é”™è¯¯è€Œå†™çš„
                            data['right_next'] = self.pts2render(data['right_next'], bg_color=self.bg_color)
                            next_render_rgb_right = data['right_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,128, 128, 3]
                            loss_dyna_leader = l2_loss(next_render_rgb_right, next_gt_rgb)

                        # RGB pre = leader( right ) + follower
                        loss_LF = loss_dyna_leader * self.cfg.lambda_dyna_leader + loss_dyna_follower * (1-self.cfg.lambda_dyna_leader)
                        loss_dyna = loss_LF 
                        # é¢„çƒ­æ­¥æ•°ï¼ˆ3000æ­¥ä»¥åŽç®—ä¸Šäº†ï¼‰
                        lambda_dyna = self.cfg.lambda_dyna if step >= self.cfg.next_mlp.warm_up else 0.                    
    
                        # Step 3 Loss(LGeo? + L embed/L sem + L dyna) = loss_rgb + self.cfg.lambda_embed * loss_embed + lambda_dyna * loss_dyna
                        loss += lambda_dyna * loss_dyna
                        loss_dyna_mask = torch.tensor(0.)
                        loss_reg = torch.tensor(0.)

                    else:
                        loss_dyna = torch.tensor(0.)
                        loss_reg = torch.tensor(0.)      
                        loss_LF = torch.tensor(0.)
                        loss_dyna_mask = torch.tensor(0.)
                elif not self.use_nerf_picture: 
                    if self.use_dynamic_field and (next_gt_rgb is not None and gt_mask is not None):
                        # æ³¨æ„ï¼šè¿™é‡Œçš„å›¾ç‰‡éƒ½æ˜¯256*256çš„
                        # right_min, right_max, left_min, left_max = 53, 73, 94, 114

                        # # # [1,1,128,128] -> [1,128,128,1] -> [1,128,128,3]
                        # gt_mask1 = gt_mask.squeeze(-1) # [1,256,256]
                        # # åˆå§‹åŒ–ç‹¬çƒ­ç¼–ç å¼ é‡ bg:[0,0,0]   right:[0,1,0]  left:[0,0,1]
                        # gt_mask_label = torch.zeros((*gt_mask1.shape, self.num_classes), dtype=torch.float32) # [1,256,256,3]
                        # # å°†æ ‡ç­¾è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç 
                        # bg_mask = (gt_mask1 < right_min) | ((gt_mask1 > right_max) & (gt_mask1 < left_min)) | (gt_mask1 > left_max)
                        # gt_mask_label[bg_mask] = torch.tensor([1, 0, 0], dtype=torch.float32)
                        # right_mask = (gt_mask1 > right_min - 1) & (gt_mask1 < right_max + 1)
                        # gt_mask_label[right_mask] = torch.tensor([0, 1, 0], dtype=torch.float32)  # å³æ‰‹çš„ç‹¬çƒ­ç¼–ç                   
                        # left_mask = (gt_mask1 > left_min - 1) & (gt_mask1 < left_max + 1)
                        # gt_mask_label[left_mask] = torch.tensor([0, 0, 1], dtype=torch.float32) 

                        # gt_mask1 = next_gt_mask.squeeze(-1) # [1,256,256]
                        # # åˆå§‹åŒ–ç‹¬çƒ­ç¼–ç å¼ é‡ bg:[0,0,0]   right:[0,1,0]  left:[0,0,1]
                        # next_gt_mask_label = torch.zeros((*gt_mask1.shape, self.num_classes), dtype=torch.float32) # [1,256,256,3]
                        # # å°†æ ‡ç­¾è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç 
                        # bg_mask = (gt_mask1 < right_min) | ((gt_mask1 > right_max) & (gt_mask1 < left_min)) | (gt_mask1 > left_max)
                        # next_gt_mask_label[bg_mask] = torch.tensor([1, 0, 0], dtype=torch.float32)
                        # right_mask = (gt_mask1 > right_min - 1) & (gt_mask1 < right_max + 1)
                        # next_gt_mask_label[right_mask] = torch.tensor([0, 1, 0], dtype=torch.float32)  # å³æ‰‹çš„ç‹¬çƒ­ç¼–ç                   
                        # left_mask = (gt_mask1 > left_min - 1) & (gt_mask1 < left_max + 1)
                        # next_gt_mask_label[left_mask] = torch.tensor([0, 0, 1], dtype=torch.float32) 

                        # gt_mask_label = self.mask_onehot(gt_mask) # 100 010  001
                        # next_gt_mask_label = self.mask_onehot(next_gt_mask) # [1 256 256 3]
                        # device = gt_mask.device  # èŽ·å– next_gt_rgb çš„è®¾å¤‡
                        # gt_mask_label = gt_mask_label.to(device)
                        # next_gt_mask_label = next_gt_mask_label.to(device)

                        next_gt_mask_label = self.mask_label(next_gt_mask)                        
                        print("next_gt_mask_label = ",next_gt_mask_label.shape,next_gt_mask_label)
                        # # 1 å½“å‰åœºæ™¯çš„mask è®­ç»ƒ  loss_dyna_mask_novel
                        # data =self.pts2render_mask_gen(data, bg_color=self.bg_mask)
                        # render_mask_novel = data['novel_view']['mask_gen'] # .permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]                           
                        # # å¿½ç•¥ç‰¹å®šçš„æ ‡ç­¾ï¼ˆä¾‹å¦‚ç©ºç™½èƒŒæ™¯ç±»ï¼‰
                        # # CrossEntropyLoss = nn.CrossEntropyLoss(ignore_index=self.ignore_label)
                        # # æŽ¥æ”¶ä¸¤ä¸ªå‚æ•°ï¼šlogitï¼ˆæ¨¡åž‹è¾“å‡ºçš„ logitsï¼‰å’Œ labelï¼ˆçœŸå®žæ ‡ç­¾ï¼‰
                        # # abel è¢«å‡åŽ» 1ã€‚è¿™ä¸ªæ“ä½œæ˜¯ä¸ºäº†å°†èƒŒæ™¯ç±»ï¼ˆé€šå¸¸ ID ä¸º 0ï¼‰è½¬ç§»åˆ° -1ï¼Œä½¿å¾— CrossEntropyLoss å¯ä»¥æ­£ç¡®å¿½ç•¥è¿™ä¸ªç±»åˆ«ã€‚
                        # # crossentropy_loss = lambda logit, label: CrossEntropyLoss(logit, label-1)
                        # loss_dyna_mask_novel = self.CrossEntropyLoss(render_mask_novel, gt_mask_label) # maskçŽ°é˜¶æ®µçš„
                        # render_mask_novel = render_mask_novel.permute(0, 2, 3, 1)

                        # 2 GRB total(Follower)  å…ˆå¯¹lefté¢„æµ‹ï¼ˆæœ€åŽçš„ç»“æžœï¼‰ loss_dyna_follower  å·¦è‡‚ RGB Loss   
                        # ä¹Ÿå¯ä»¥è¯´æ˜¯åŒæ‰‹ç»“æžœ
                        if ('xyz_maps' in data['left_next']):
                            data['left_next'] = self.pts2render(data['left_next'], bg_color=self.bg_color)
                            next_render_novel = data['left_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]
                            loss_dyna_follower = l2_loss(next_render_novel, next_gt_rgb) # åŒè‡‚ç»“æžœé¢„æµ‹

                        # 3 next mask train (pre - left(mask) ) next_loss_dyna_mask_left  å·¦è‡‚ Mask Loss
                        data['left_next'] =self.pts2render_mask_gen(data['left_next'], bg_color=self.bg_mask)
                        next_render_mask = data['left_next']['novel_view']['mask_gen'] # .permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]
                        # print('next_render_mask', next_render_mask.shape,next_gt_mask_label.shape)
                        next_loss_dyna_mask_left = self.CrossEntropyLoss(next_render_mask, next_gt_mask_label) # maskåŽ»å·¦è‡‚çš„mask
                        next_render_mask = next_render_mask.permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]

                        # gen mask and exclude
                        # data['left_next'] =self.pts2render_mask_gen(data['left_next'], bg_color=self.bg_color)
                        # next_left_mask_gen = data['left_next']['novel_view']['mask_gen'].permute(0, 2, 3, 1)        

                        # exclude_left_mask = self.generate_final_class_labels(next_render_mask) # ?æ„Ÿè§‰æœ‰é—®é¢˜ï¼Œç”¨gtè¿˜æ˜¯genï¼Ÿ
                        # [1,256,256,3]
                        # exclude_left_mask = self.generate_final_class_labels(next_gt_mask_label) # ?æ„Ÿè§‰æœ‰é—®é¢˜ï¼Œç”¨gtè¿˜æ˜¯genï¼Ÿ ç”¨gt å› ä¸ºè¿™æ˜¯å¯¹è¾“å‡ºçš„è®¡ç®—
                        exclude_left_mask = self.generate_final_class_labels(next_render_mask) 
                        # print('exclude_left_mask', exclude_left_mask.shape) # [1 256 256]
                        # print("next_gt_rgb",next_gt_rgb.shape)              # [1 256 256 3]
                        exclude_left_mask = exclude_left_mask.unsqueeze(3).repeat(1, 1, 1, 3) # [1 256 256] -> [1 256 256 1] -> [1 256 256 3]
                        result_right_image = next_gt_rgb * exclude_left_mask # åæ­£èƒŒæ™¯éƒ½æ˜¯Falseä¸ç”¨åŠ 

                        #  4 RGB loss_dyna_leader leader  åˆ©ç”¨å‰é¢å¾—åˆ°çš„maskåˆ åŽ»å·¦è‡‚
                        if ('xyz_maps' in data['right_next']):
                            data['right_next'] = self.pts2render(data['right_next'], bg_color=self.bg_color)
                            next_render_rgb_right = data['right_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,128, 128, 3]
                            next_render_novel_mask = next_render_rgb_right * exclude_left_mask  # åŽŸæ¥ç”¨é”™äº†...  next_gt_rgb -> next_render_rgb_right
                            loss_dyna_leader = l2_loss(next_render_novel_mask, result_right_image)
                        
                        # 5 Mask loss_dyna_mask_next_right å³è‡‚maskè®­ç»ƒï¼ˆå’Œnowä¸€æ · æ— ç”¨ï¼‰
                        data['right_next'] =self.pts2render_mask_gen(data['right_next'], bg_color=self.bg_mask)
                        next_render_mask_right = data['right_next']['novel_view']['mask_gen'] # .permute(0, 2, 3, 1)
                        # CrossEntropyLoss = nn.CrossEntropyLoss(ignore_index=self.ignore_label)
                        next_loss_dyna_mask_right = self.CrossEntropyLoss(next_render_mask_right, next_gt_mask_label)
                        next_render_mask_right = next_render_mask_right.permute(0, 2, 3, 1) # [1,128, 128, 3]

                        # pre mask = right +left    
                        next_loss_dyna_mask = next_loss_dyna_mask_left * ( 1 - self.cfg.lambda_mask_right ) + next_loss_dyna_mask_right * self.cfg.lambda_mask_right  # å³è‡‚æƒé‡å°ä¸€ç‚¹
                        
                        # MASK = now +pre
                        # loss_dyna_mask = loss_dyna_mask_novel * (1 - self.cfg.lambda_next_loss_mask)  + next_loss_dyna_mask * self.cfg.lambda_next_loss_mask
                        loss_dyna_mask = loss_dyna_mask_novel * (1 - self.cfg.lambda_next_loss_mask)  + next_loss_dyna_mask * self.cfg.lambda_next_loss_mask


                        # RGB pre = leader( right ) + follower
                        loss_LF = loss_dyna_leader * self.cfg.lambda_dyna_leader + loss_dyna_follower * (1-self.cfg.lambda_dyna_leader)
                        # print('loss_LF = ', loss_LF, loss_dyna_leader, loss_dyna_follower)
                        loss_dyna = loss_LF * (1-self.cfg.lambda_mask) + loss_dyna_mask * self.cfg.lambda_mask 
                        # print('loss_dyna = ', loss_dyna,loss_LF,loss_dyna_mask)
                        # é¢„çƒ­æ­¥æ•°ï¼ˆ3000æ­¥ä»¥åŽç®—ä¸Šäº†ï¼‰
                        lambda_dyna = self.cfg.lambda_dyna if step >= self.cfg.next_mlp.warm_up else 0.                    
                        
                        # Step 3 Loss(LGeo? + L embed/L sem + L dyna) = loss_rgb + self.cfg.lambda_embed * loss_embed + lambda_dyna * loss_dyna
                        loss += lambda_dyna * loss_dyna

                        loss_reg = torch.tensor(0.)
                    else:
                        loss_dyna = torch.tensor(0.)
                        loss_reg = torch.tensor(0.)      
                        loss_LF = torch.tensor(0.)
                        # loss_dyna_mask = torch.tensor(0.) 

            loss_dict = {
                'loss': loss,
                'loss_rgb': loss_rgb.item(),
                'loss_embed': loss_embed.item(),
                'loss_dyna': loss_dyna.item(),
                'loss_LF': loss_LF.item(),
                'loss_dyna_mask': loss_dyna_mask.item(),
                'loss_reg': loss_reg.item(),
                'l1': Ll1.item(),
                'psnr': psnr.item(),
                }
        else: # not training ï¼ˆç¬¬0æ¬¡æ˜¯èµ°è¿™è¾¹çš„ï¼‰
            # æ— çœŸå®žæ•°æ®ï¼Œæ¸²æŸ“ï¼ˆæŽ¨ç†ï¼‰
            # no ground-truth given, rendering (inference) 
            with torch.no_grad():
                # Gaussian Generator
                data = self.gs_model(data)
                # Gaussian Render
                data = self.pts2render(data, bg_color=self.bg_color) # default: [0, 0, 0]
                # å½“å‰åœºæ™¯
                render_novel = data['novel_view']['img_pred'].permute(0, 2, 3, 1) # channel last
                # è¯­ä¹‰ç‰¹å¾
                render_embed = data['novel_view']['embed_pred'].permute(0, 2, 3, 1)
                
                # æœªæ¥é¢„æµ‹
                if self.field_type == 'bimanual':
                    if self.use_dynamic_field and 'xyz_maps' in data['next']:
                        data['next'] = self.pts2render(data['next'], bg_color=self.bg_color)
                        next_render_novel = data['next']['novel_view']['img_pred'].permute(0, 2, 3, 1)
                else:
                    if self.mask_gen == 'gt':
                        if self.use_dynamic_field:
                            # start_time = time.perf_counter()
                            # print("#0 time1: ", start_time)
                            # å·¦æ‰‹çš„ç‚¹äº‘
                            mask_3d, next_mask_3d = self.createby_gt_mask(data=data, 
                                gt_mask=gt_mask,next_gt_mask=next_gt_mask, 
                                gt_mask_camera_extrinsic=gt_mask_camera_extrinsic, gt_mask_camera_intrinsic=gt_mask_camera_intrinsic,  
                                gt_maskdepth=gt_maskdepth, next_gt_maskdepth=next_gt_maskdepth)
                            # start_time = time.perf_counter()
                            # print("#0 time2: ", start_time)                            
                            # æŠ•å½±åˆ°äºŒç»´
                            projected_points = project_3d_to_2d(next_mask_3d, next_gt_intrinsic)
                            # åˆ›å»ºäºŒç»´æŽ©ç 
                            mask_shape = (128,128) # (256, 256)  # å‡è®¾çš„æŽ©ç å¤§å°
                            # start_time = time.perf_counter()
                            # print("#0 time3: ", start_time)
                            exclude_left_mask = create_2d_mask_from_convex_hull(projected_points, mask_shape)
                            exclude_left_mask = exclude_left_mask.unsqueeze(0).unsqueeze(-1).repeat(1, 1, 1, 3) # [1,256,256,3]
                            # exclude_left_mask = exclude_left_mask.permute(0, 3, 1, 2) # [1,3,256,256]
                            # exclude_left_mask = F.interpolate(exclude_left_mask, size=(128, 128), mode='bilinear', align_corners=False)
                            # exclude_left_mask = exclude_left_mask.permute(0, 2, 3, 1) # [1,128,128,3]
                            # final_time = time.perf_counter()
                            # print("#0 time4: ", final_time)
                            # exclude_left_mask = exclude_left_mask.unsqueeze(0).unsqueeze(-1).repeat(1, 1, 1, 3)
                            if next_gt_rgb is not None:
                                device = next_gt_rgb.device  # èŽ·å– next_gt_rgb çš„è®¾å¤‡
                                exclude_left_mask = exclude_left_mask.to(device)
                                next_render_mask = exclude_left_mask
                                result_right_image = next_gt_rgb * exclude_left_mask  
                                render_mask_novel = result_right_image

                            # 2 GRB total(Follower)  å…ˆå¯¹lefté¢„æµ‹ï¼ˆæœ€åŽçš„ç»“æžœï¼‰ loss_dyna_follower  å·¦è‡‚ RGB Loss   
                            # ä¹Ÿå¯ä»¥è¯´æ˜¯åŒæ‰‹ç»“æžœ
                            if ('xyz_maps' in data['left_next']):
                                data['left_next'] = self.pts2render(data['left_next'], bg_color=self.bg_color)
                                next_render_novel = data['left_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]
                            
                            #  4 RGB loss_dyna_leader leader  åˆ©ç”¨å‰é¢å¾—åˆ°çš„maskåˆ åŽ»å·¦è‡‚
                            if ('xyz_maps' in data['right_next']):
                                # with torch.no_grad():  åŽŸæ¥ä¸ºäº†æœ‰çš„Lossæ²¡è®¡ç®—æŠ¥æ— å›žä¼ é”™è¯¯è€Œå†™çš„
                                data['right_next'] = self.pts2render(data['right_next'], bg_color=self.bg_color)
                                next_render_rgb_right = data['right_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,128, 128, 3]                                
                    elif self.mask_gen == 'pre':   # LF + è‡ªå·± train mask   
                        data =self.pts2render_mask(data, bg_color=self.bg_mask)
                        if self.use_CEloss==1 or self.use_CEloss==3 or self.use_CEloss == 7 or self.use_CEloss == 21:
                            render_mask_novel = data['novel_view']['mask_pred'].permute(0, 2, 3, 1)
                            ## !! render_mask_novel = render_novel * render_mask_gtrgb
                            render_mask_gtrgb = self.generate_final_class_labels(render_mask_novel).unsqueeze(3).repeat(1, 1, 1, 3)     # 1 128 128 3 [TTT/FFF]                        
                            render_mask_gtrgb = gt_rgb * render_mask_gtrgb
                            # vis render
                            render_mask_novel = self.vis_labels(render_mask_novel)
                            
                            gt_mask1 = self.mask_onehot(gt_mask) # 1 128 128 1[1,200] -> 1 128 128 3[100 010 001] 
                            gt_mask_vis =  self.vis_labels(gt_mask1)
                            # vis rgb render in mask camera å¯è§†åŒ–maskç›¸æœºçš„rgb  
                            data =self.pts2render_rgb(data, bg_color=self.bg_color)
                            ## !! 
                            next_render_mask = data['mask_view']['rgb_pred'].permute(0, 2, 3, 1)

                        if self.use_CEloss==2: # æœªæ”¹
                            render_mask_novel = data['novel_view']['mask_pred'].permute(0, 2, 3, 1)  # 1 128 128 3
                            render_mask_novel1 = render_mask_novel
                            print("render_mask_novel",render_mask_novel.shape) # [1 128 128 3]
                            render_mask_novel = self.generate_final_class_labels_ce1(render_mask_novel) # [1 128 128] 0/1
                            next_render_mask_right = self.vis_labels_ce1(render_mask_novel1)

                            # render_mask_novel = self.generate_final_class_labels(render_mask_novel1) # 1 128 128
                            render_mask_novel = render_mask_novel.unsqueeze(3).repeat(1, 1, 1, 3)   # 1 128 128 3
                            render_mask_gtrgb = gt_rgb * render_mask_novel
                            render_mask_novel = render_novel * render_mask_novel

                            # gt
                            gt_mask1 = self.mask_onehot(gt_mask)  # 1 128 128 3
                            # gt_mask1 =gt_mask1.permute(0, 3, 1, 2)
                            print("gt_mask1",gt_mask1.shape,gt_mask1) # 1 128 128 3 
                            next_render_rgb_right =  self.vis_labels(gt_mask1)
                        elif self.use_CEloss == 0: # l1
                            render_mask_novel = data['novel_view']['mask_pred'].permute(0, 2, 3, 1) # 1 128 128 3
                            render_mask_novel = (render_mask_novel / 2 + 0.5)*(self.num_classes-1)  # [0 , 2]
                            ## !! 
                            next_render_mask_right = self.vis_labelsL1(render_mask_novel)           #
                            render_mask_novel = self.generate_final_class_labels_L1(render_mask_novel)

                            # vis gt left 
                            ## !! 
                            gt_mask_vis = self.vis_labelsL1(gt_mask_label)
                            ## 
                            next_render_rgb_right  = self.generate_final_class_labels_L1(gt_mask_label)
                            ## 
                            next_render_rgb_right = gt_rgb * next_render_rgb_right
                            
                            render_mask_gtrgb = gt_rgb * render_mask_novel
                            render_mask_novel = render_novel * render_mask_novel

                        elif self.use_CEloss == 4:
                            render_mask_novel = render_novel
                            render_mask_novel = render_mask_novel*(self.num_classes-1)
                            next_render_mask_right = self.vis_labelsL1(render_mask_novel) # debug çš„æ—¶å€™ç”¨ä¸€ä¸‹
                            # render_mask_novel = self.generate_final_class_labels(render_mask_novel)
                            # render_mask_novel = render_mask_novel.unsqueeze(3).repeat(1, 1, 1, 3)
                            render_mask_novel = self.generate_final_class_labels_L1(render_mask_novel)

                            # å¯è§†åŒ–gt left ä½†æ˜¯
                            next_render_mask = self.vis_labelsL1(gt_mask_label)
                            next_render_rgb_right  = self.generate_final_class_labels_L1(gt_mask_label)
                            next_render_rgb_right = gt_rgb * next_render_rgb_right
                            
                            render_mask_gtrgb = gt_rgb * render_mask_novel
                            print("render_mask_novel = ",render_mask_novel.shape,render_mask_novel)
                            render_mask_novel = render_novel * render_mask_novel                           
                        elif self.use_CEloss == 5:
                            data =self.pts2render1(data, bg_color=self.bg_color)
                            render_mask_novel = data['novel_view']['embed_pred'].permute(0, 2, 3, 1) 
                            print("1 render_mask_novel = ",render_mask_novel.shape, render_mask_novel)
                            render_mask_novel = render_mask_novel*(self.num_classes-1)
                            print("2 render_mask_novel = ",render_mask_novel.shape, render_mask_novel)
                            next_render_mask_right = self.vis_labelsL1(render_mask_novel) # debug çš„æ—¶å€™ç”¨ä¸€ä¸‹

                            render_mask_novel = self.generate_final_class_labels_L1(render_mask_novel)

                            # å¯è§†åŒ–gt left ä½†æ˜¯
                            next_render_mask = self.vis_labelsL1(gt_mask_label)
                            next_render_rgb_right  = self.generate_final_class_labels_L1(gt_mask_label)
                            next_render_rgb_right = gt_rgb * next_render_rgb_right
                            
                            render_mask_gtrgb = gt_rgb * render_mask_novel

                            render_mask_novel = render_novel * render_mask_novel    
                        elif self.use_CEloss == 6:
                            print("only rgb")                          

                        if self.use_dynamic_field:
                            # 2 next Left RGB     
                            if ('xyz_maps' in data['left_next']):
                                data['left_next'] = self.pts2render(data['left_next'], bg_color=self.bg_color)
                                next_render_novel = data['left_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]
                            
                            # 3 next Left mask
                                # data['left_next'] =self.pts2render_mask(data['left_next'], bg_color=self.bg_mask)
                                # next_render_mask = data['left_next']['novel_view']['mask_pred'].permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]
                                # next_render_mask = self.generate_final_class_labels(next_render_mask)
                                # next_render_mask = next_render_mask.unsqueeze(3).repeat(1, 1, 1, 3)
                                # next_render_mask = next_render_novel * next_render_mask
                            
                            data['left_next'] =self.pts2render_mask(data['left_next'], bg_color=self.bg_mask)
                            data['left_next'] =self.pts2render_mask_gen(data['left_next'], bg_color=self.bg_mask)
                            if self.use_CEloss==1 or self.use_CEloss == 7 or self.use_CEloss == 21:
                                next_render_mask = data['left_next']['novel_view']['mask_pred'].permute(0, 2, 3, 1) 
                                next_render_mask = self.vis_labels(next_render_mask)
                                # gen exclude
                                next_left_mask_gen = data['left_next']['novel_view']['mask_gen'].permute(0, 2, 3, 1)  # 1 128 128 3   
                                exclude_left_mask = self.generate_final_class_labels(next_left_mask_gen).unsqueeze(3).repeat(1, 1, 1, 3)
                                next_left_mask_gen = self.vis_labels(next_left_mask_gen)
                                next_gt_mask1 = self.mask_onehot(next_gt_mask) # 1 128 128 1[1,200] -> 1 128 128 3[100 010 001] 
                                next_gt_mask_vis =  self.vis_labels(next_gt_mask1)
                            elif self.use_CEloss == 0:     # Ll1
                                next_render_mask = data['left_next']['novel_view']['mask_pred'].permute(0, 2, 3, 1) # 1 128 128 3(rgb label mean-> 0 1 2)
                                next_render_mask = (next_render_mask / 2 + 0.5  )*(self.num_classes-1)    
                                next_render_mask = self.vis_labelsL1(next_render_mask)
                                next_left_mask_gen = data['left_next']['novel_view']['mask_gen'].permute(0, 2, 3, 1) # 1 128 128 3
                                next_left_mask_gen = (next_left_mask_gen / 2 + 0.5  )*(self.num_classes-1)           # 1 128 128 3 [0,2]
                                exclude_left_mask = self.generate_final_class_labels_L1(next_left_mask_gen)
                                next_left_mask_gen = self.vis_labelsL1(next_left_mask_gen)
                                next_gt_mask_vis = self.vis_labelsL1(next_gt_mask_label)
                            exclude_left_mask = exclude_left_mask * next_render_novel


                            # left gen mask
                                # data['left_next'] =self.pts2render_mask_gen(data['left_next'], bg_color=self.bg_mask)
                                # next_left_mask_gen = data['left_next']['novel_view']['mask_gen'].permute(0, 2, 3, 1)
                                # exclude_left_mask = self.generate_final_class_labels(next_left_mask_gen).unsqueeze(3).repeat(1, 1, 1, 3) 
                                # next_left_mask_gen = self.vis_labels(next_left_mask_gen)

                            #  4 RGB loss_dyna_leader leader  åˆ©ç”¨å‰é¢å¾—åˆ°çš„maskåˆ åŽ»å·¦è‡‚
                            if ('xyz_maps' in data['right_next']):
                                # with torch.no_grad():  åŽŸæ¥ä¸ºäº†æœ‰çš„Lossæ²¡è®¡ç®—æŠ¥æ— å›žä¼ é”™è¯¯è€Œå†™çš„
                                data['right_next'] = self.pts2render(data['right_next'], bg_color=self.bg_color)
                                next_render_rgb_right = data['right_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,128, 128, 3]
                                # 1
                            # 5 Mask loss_dyna_mask_next_right å³è‡‚maskè®­ç»ƒï¼ˆå’Œnowä¸€æ · æ— ç”¨ï¼‰
                                # next_render_mask_right = data['right_next']['novel_view']['mask_pred'].permute(0, 2, 3, 1)
                            data['right_next'] =self.pts2render_mask(data['right_next'], bg_color=self.bg_mask)
                            next_render_mask_right = data['right_next']['novel_view']['mask_pred'].permute(0, 2, 3, 1) 
                            if self.use_CEloss==1 or self.use_CEloss == 7 or self.use_CEloss == 21:
                                next_render_mask_right = self.vis_labels(next_render_mask_right)
                            elif self.use_CEloss == 0:     # Ll1
                                next_render_mask_right = (next_render_mask_right / 2 + 0.5  )*(self.num_classes-1) 
                                next_render_mask_right = self.vis_labelsL1(next_render_mask_right)

                            ## test
                                # next_render_mask_right = self.vis_labels(next_render_mask_right)
                            # next_render_mask_right = self.vis_labels(next_render_mask_right).unsqueeze(3).repeat(1, 1, 1, 3)
                            # next_render_mask_right = next_render_rgb_right * next_render_mask_right

                    elif self.mask_gen == 'None':
                        if self.use_dynamic_field :
                            # 2 GRB total(Follower)  å…ˆå¯¹lefté¢„æµ‹ï¼ˆæœ€åŽçš„ç»“æžœï¼‰ loss_dyna_follower  å·¦è‡‚ RGB Loss   
                            # ä¹Ÿå¯ä»¥è¯´æ˜¯åŒæ‰‹ç»“æžœ
                            if ('xyz_maps' in data['left_next']):
                                data['left_next'] = self.pts2render(data['left_next'], bg_color=self.bg_color)
                                next_render_novel = data['left_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]

                            #  4 RGB loss_dyna_leader leader  åˆ©ç”¨å‰é¢å¾—åˆ°çš„maskåˆ åŽ»å·¦è‡‚
                            if ('xyz_maps' in data['right_next']):
                                # with torch.no_grad():  åŽŸæ¥ä¸ºäº†æœ‰çš„Lossæ²¡è®¡ç®—æŠ¥æ— å›žä¼ é”™è¯¯è€Œå†™çš„
                                data['right_next'] = self.pts2render(data['right_next'], bg_color=self.bg_color)
                                next_render_rgb_right = data['right_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,128, 128, 3]
                    elif not self.use_nerf_picture: 
                        gt_rgb = gt_rgb.permute(0,2,3,1) # [1, 3, 256, 256] ->[1, 256, 256, 3]
                        gt_mask =gt_mask.permute(0,2,3,1)
                        gt_mask_label = self.mask_onehot(gt_mask)
                        data =self.pts2render_mask_gen(data, bg_color=self.bg_mask)
                        render_mask_novel = data['novel_view']['mask_gen'].permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]                           
                        # print("1",render_mask_novel.shape,render_mask_novel) # [1,256,256,3]
                        render_mask_novel = self.generate_final_class_labels(render_mask_novel)
                        # print("2",render_mask_novel.shape,render_mask_novel) # [1,3, 256,256]
                        render_mask_novel = render_mask_novel.unsqueeze(3).repeat(1, 1, 1, 3)
                        # render_mask_gtrgb = gt_rgb * render_mask_novel
                        render_mask_novel = render_novel * render_mask_novel # åæ­£èƒŒæ™¯éƒ½æ˜¯Falseä¸ç”¨åŠ 
                        

                        if self.use_dynamic_field and (next_gt_rgb is not None and gt_mask is not None):
                            next_gt_rgb = next_gt_rgb.permute(0,2,3,1)
                            next_gt_mask = next_gt_mask.permute(0,2,3,1)
                            # æ³¨æ„ï¼šè¿™é‡Œçš„å›¾ç‰‡éƒ½æ˜¯256*256çš„
                            next_gt_mask_label = self.mask_onehot(next_gt_mask)
                            # device = gt_mask.device  # èŽ·å– next_gt_rgb çš„è®¾å¤‡
                            # gt_mask_label = gt_mask_label.to(device)
                            # next_gt_mask_label = next_gt_mask_label.to(device)
                            # 1 å½“å‰åœºæ™¯çš„mask è®­ç»ƒ  loss_dyna_mask_novel

                            # 2 GRB total(Follower)  å…ˆå¯¹lefté¢„æµ‹ï¼ˆæœ€åŽçš„ç»“æžœï¼‰ loss_dyna_follower  å·¦è‡‚ RGB Loss   
                            # ä¹Ÿå¯ä»¥è¯´æ˜¯åŒæ‰‹ç»“æžœ
                            if ('xyz_maps' in data['left_next']):
                                data['left_next'] = self.pts2render(data['left_next'], bg_color=self.bg_color)
                                next_render_novel = data['left_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]
                                # loss_dyna_follower = l2_loss(next_render_novel, next_gt_rgb) # åŒè‡‚ç»“æžœé¢„æµ‹

                            # 3 next mask train (pre - left(mask) ) next_loss_dyna_mask_left  å·¦è‡‚ Mask Loss
                            data['left_next'] =self.pts2render_mask_gen(data['left_next'], bg_color=self.bg_mask)
                            next_render_mask = data['left_next']['novel_view']['mask_gen'].permute(0, 2, 3, 1) # [1,3ï¼Œ128, 128] -> [1,128, 128, 3]
                            exclude_left_mask = self.generate_final_class_labels(next_render_mask) # ?æ„Ÿè§‰æœ‰é—®é¢˜ï¼Œç”¨gtè¿˜æ˜¯genï¼Ÿ ç”¨gt å› ä¸ºè¿™æ˜¯å¯¹è¾“å‡ºçš„è®¡ç®—
                            exclude_left_mask = exclude_left_mask.unsqueeze(3).repeat(1, 1, 1, 3)
                            result_right_image = next_render_novel * exclude_left_mask # åæ­£èƒŒæ™¯éƒ½æ˜¯Falseä¸ç”¨åŠ 
                            next_render_mask = result_right_image

                            # gen mask and exclude
                            # data['left_next'] =self.pts2render_mask_gen(data['left_next'], bg_color=self.bg_color)
                            # next_left_mask_gen = data['left_next']['novel_view']['mask_gen'].permute(0, 2, 3, 1)        

                            # exclude_left_mask = self.generate_final_class_labels(next_render_mask) # ?æ„Ÿè§‰æœ‰é—®é¢˜ï¼Œç”¨gtè¿˜æ˜¯genï¼Ÿ
                            # print("next_gt_mask_label",next_gt_mask_label.shape,next_gt_mask_label)
                            exclude_left_mask = self.generate_final_class_labels(next_gt_mask_label) #[1 256 256 3] ?æ„Ÿè§‰æœ‰é—®é¢˜ï¼Œç”¨gtè¿˜æ˜¯genï¼Ÿ ç”¨gt å› ä¸ºè¿™æ˜¯å¯¹è¾“å‡ºçš„è®¡ç®—
                            exclude_left_mask = exclude_left_mask.unsqueeze(3).repeat(1, 1, 1, 3)
                            # next_gt_rgb = next_gt_rgb.permute(0, 2, 3, 1)
                            device = next_gt_rgb.device  # èŽ·å– next_gt_rgb çš„è®¾å¤‡
                            # ç¡®ä¿ exclude_left_mask åœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Š
                            exclude_left_mask = exclude_left_mask.to(device)
                            # result_right_image = next_gt_rgb * exclude_left_mask # ï¼ˆgtï¼‰
                            next_left_mask_gen = next_gt_rgb * exclude_left_mask # ï¼ˆgtï¼‰

                            #  4 RGB loss_dyna_leader leader  åˆ©ç”¨å‰é¢å¾—åˆ°çš„maskåˆ åŽ»å·¦è‡‚
                            if ('xyz_maps' in data['right_next']):
                                data['right_next'] = self.pts2render(data['right_next'], bg_color=self.bg_color)
                                next_render_rgb_right = data['right_next']['novel_view']['img_pred'].permute(0, 2, 3, 1) # [1,128, 128, 3]
                                next_render_novel_mask = next_render_rgb_right * exclude_left_mask  # åŽŸæ¥ç”¨é”™äº†...  next_gt_rgb -> next_render_rgb_right
                            
                            # 5 Mask loss_dyna_mask_next_right å³è‡‚maskè®­ç»ƒï¼ˆå’Œnowä¸€æ · æ— ç”¨ï¼‰
                            data['right_next'] =self.pts2render_mask_gen(data['right_next'], bg_color=self.bg_color)
                            next_render_mask_right = data['right_next']['novel_view']['mask_gen'].permute(0, 2, 3, 1)
                            exclude_right_mask = self.generate_final_class_labels(next_render_mask_right) # ?æ„Ÿè§‰æœ‰é—®é¢˜ï¼Œç”¨gtè¿˜æ˜¯genï¼Ÿ ç”¨gt å› ä¸ºè¿™æ˜¯å¯¹è¾“å‡ºçš„è®¡ç®—
                            exclude_right_mask = exclude_right_mask.unsqueeze(3).repeat(1, 1, 1, 3)
                            result_right_image = next_gt_rgb * exclude_right_mask # åæ­£èƒŒæ™¯éƒ½æ˜¯Falseä¸ç”¨åŠ 
                            next_render_mask_right = result_right_image

                loss_dict = {
                    'loss': 0.,
                    'loss_rgb': 0.,
                    'loss_embed': 0.,
                    'loss_dyna': 0.,
                    'loss_LF':  0.,
                    'loss_dyna_mask':  0.,
                    'loss_reg': 0.,
                    'l1': 0.,
                    'psnr': 0.,
                }

        # get Gaussian embedding èŽ·å¾—é«˜æ–¯åµŒå…¥
        # dotmap å…è®¸ä½¿ç”¨ç‚¹ï¼ˆ.ï¼‰ç¬¦å·æ¥è®¿é—®å­—å…¸ä¸­çš„é”®
        ret_dict = DotMap(render_novel=render_novel, next_render_novel=next_render_novel,
                          render_embed=render_embed, gt_embed=gt_embed, 
                          render_mask_novel = render_mask_novel,           # now mask * render_rgb
                          render_mask_gtrgb = render_mask_gtrgb,           # now mask * gt_rgb
                        next_render_mask = next_render_mask,               # å·¦è‡‚mask * next_render_novel
                        next_render_mask_right = next_render_mask_right,   # æ— ç”¨ å³è‡‚mask 
                        next_render_rgb_right = next_render_rgb_right,            # å³è‡‚next rgb
                        next_left_mask_gen = next_left_mask_gen, 
                        exclude_left_mask =exclude_left_mask,                      # ç”Ÿæˆçš„å·¦è‡‚å½“æ—¶è§†è§’çš„mask
                        gt_mask_vis =gt_mask_vis,
                        next_gt_mask_vis =next_gt_mask_vis,
                        )             
        # print("render_mask_novel = ",render_mask_novel.shape, render_mask_novel)

        return loss_dict, ret_dict
    
    def pts2render(self, data: dict, bg_color=[0,0,0]):
        '''use render function in GSZ åœ¨GSZ ä¸­ä½¿ç”¨æ¸²æŸ“åŠŸèƒ½(åº”è¯¥å°±æ˜¯ä½¿ç”¨å…ˆå‰é‡‡é›†çš„æ•°æ®é‡å»ºåœºæ™¯)'''
        bs = data['intr'].shape[0]
        assert bs == 1, "batch size should be 1"
        # å…¬å¼2ä¸­ æ—¶åˆ»i çš„çŠ¶æ€ï¼ˆÎ¸ å¤šäº†f é«˜çº§è¯­ä¹‰ç‰¹å¾ï¼‰
        i = 0
        xyz_i = data['xyz_maps'][i, :, :]
        feature_i = data['sh_maps'][i, :, :, :] # [16384, 4, 3]
        rot_i = data['rot_maps'][i, :, :]
        scale_i = data['scale_maps'][i, :, :]
        opacity_i = data['opacity_maps'][i, :, :]
        feature_language_i = data['feature_maps'][i, :, :]  # [B, N, 3]   [1, 65536, 3]  

        # æ¸²æŸ“è¿”å›žå­—å…¸  renderåº”è¯¥æ˜¯ç”¨æ¥æ¸²æŸ“çš„  from agents.manigaussian_bc2.gaussian_renderer import render
        render_return_dict = render(
            data, i, xyz_i, rot_i, scale_i, opacity_i, 
            bg_color=bg_color, pts_rgb=None, features_color=feature_i, features_language=feature_language_i
            )

        # .unsqueeze(0): è¿™æ˜¯PyTorchå¼ é‡çš„ä¸€ä¸ªæ“ä½œï¼Œç”¨äºŽåœ¨å¼ é‡çš„ç¬¬0ä¸ªç»´åº¦ï¼ˆå³æœ€å‰é¢ï¼‰å¢žåŠ ä¸€ä¸ªç»´åº¦ã€‚å¦‚æžœåŽŸå§‹å¼ é‡æ˜¯ä¸€ç»´çš„ï¼Œè¿™ä¸ªæ“ä½œä¼šå°†å…¶å˜æˆäºŒç»´çš„ï¼Œå…¶ä¸­æ–°åŠ çš„ç»´åº¦å¤§å°ä¸º1ã€‚
        # data['novel_view']['img_pred']: è¿™æ˜¯åœ¨ data å­—å…¸ä¸­çš„ 'novel_view' é”®ä¸‹åˆ›å»ºæˆ–æ›´æ–°ä¸€ä¸ªå­é”® 'img_pred'ã€‚è¿™ä¸ªå­é”®è¢«èµ‹å€¼ä¸º render_return_dict['render'] å¼ é‡å¢žåŠ ä¸€ä¸ªæ–°ç»´åº¦åŽçš„ç»“æžœã€‚
        data['novel_view']['img_pred'] = render_return_dict['render'].unsqueeze(0)
        data['novel_view']['embed_pred'] = render_return_dict['render_embed'].unsqueeze(0)
        return data

    def pts2render1(self, data: dict, bg_color=[0,0,0]):
        '''feature_language_iç”¨maskèµ‹å€¼'''
        bs = data['intr'].shape[0]
        assert bs == 1, "batch size should be 1"
        # å…¬å¼2ä¸­ æ—¶åˆ»i çš„çŠ¶æ€ï¼ˆÎ¸ å¤šäº†f é«˜çº§è¯­ä¹‰ç‰¹å¾ï¼‰
        i = 0
        xyz_i = data['xyz_maps'][i, :, :].detach()
        feature_i = data['sh_maps'][i, :, :, :].detach() # [16384, 4, 3]
        rot_i = data['rot_maps'][i, :, :].detach()
        scale_i = data['scale_maps'][i, :, :].detach()
        opacity_i = data['opacity_maps'][i, :, :].detach()
        feature_language_i = data['mask_maps'][i, :, :]  # [B, N, 3]   [1, 65536, 3]  

        # æ¸²æŸ“è¿”å›žå­—å…¸  renderåº”è¯¥æ˜¯ç”¨æ¥æ¸²æŸ“çš„  from agents.manigaussian_bc2.gaussian_renderer import render
        render_return_dict = render1(
            data, i, xyz_i, rot_i, scale_i, opacity_i, 
            bg_color=bg_color, pts_rgb=None, features_color=feature_i, features_language=feature_language_i
            )

        # .unsqueeze(0): è¿™æ˜¯PyTorchå¼ é‡çš„ä¸€ä¸ªæ“ä½œï¼Œç”¨äºŽåœ¨å¼ é‡çš„ç¬¬0ä¸ªç»´åº¦ï¼ˆå³æœ€å‰é¢ï¼‰å¢žåŠ ä¸€ä¸ªç»´åº¦ã€‚å¦‚æžœåŽŸå§‹å¼ é‡æ˜¯ä¸€ç»´çš„ï¼Œè¿™ä¸ªæ“ä½œä¼šå°†å…¶å˜æˆäºŒç»´çš„ï¼Œå…¶ä¸­æ–°åŠ çš„ç»´åº¦å¤§å°ä¸º1ã€‚
        # data['novel_view']['img_pred']: è¿™æ˜¯åœ¨ data å­—å…¸ä¸­çš„ 'novel_view' é”®ä¸‹åˆ›å»ºæˆ–æ›´æ–°ä¸€ä¸ªå­é”® 'img_pred'ã€‚è¿™ä¸ªå­é”®è¢«èµ‹å€¼ä¸º render_return_dict['render'] å¼ é‡å¢žåŠ ä¸€ä¸ªæ–°ç»´åº¦åŽçš„ç»“æžœã€‚
        data['novel_view']['img_pred'] = render_return_dict['render'].unsqueeze(0)
        data['novel_view']['embed_pred'] = render_return_dict['render_embed'].unsqueeze(0)
        return data

    def pts2render_mask(self, data: dict, bg_color=[0,0,0]):
        '''use render function in GSZ åœ¨GSZ ä¸­ä½¿ç”¨æ¸²æŸ“åŠŸèƒ½(åº”è¯¥å°±æ˜¯ä½¿ç”¨å…ˆå‰é‡‡é›†çš„æ•°æ®é‡å»ºåœºæ™¯)'''
        bs = data['intr'].shape[0]
        assert bs == 1, "batch size should be 1"
        # å…¬å¼2ä¸­ æ—¶åˆ»i çš„çŠ¶æ€ï¼ˆÎ¸ å¤šäº†f é«˜çº§è¯­ä¹‰ç‰¹å¾ï¼‰
        i = 0
        xyz_i = data['xyz_maps'][i, :, :].detach() 
        feature_i = data['sh_maps'][i, :, :, :].detach()  # [16384, 4, 3]
        rot_i = data['rot_maps'][i, :, :].detach() 
        scale_i = data['scale_maps'][i, :, :].detach() 
        opacity_i = data['opacity_maps'][i, :, :].detach() 
        precomputed_mask_i = data['mask_maps'][i, :, :] # mask  [1, 65536, 3]
        # precomputed_mask_i = precomputed_mask_i.reshape(1,256,256,3).permute(0,3,1,2) # [1, 65536, 3] -> [1, 3, 256, 256]
        # if self.mask_gen =='pre':    
            # precomputed_mask_i = F.interpolate(precomputed_mask_i, size=(128, 128), mode='bilinear', align_corners=False) # [1 3 256 256] -> [1 3 128 128]
        # precomputed_mask_i = precomputed_mask_i.squeeze(0).permute(1,2,0)
        feature_language_i = data['feature_maps'][i, :, :].detach()   # [B, N, 3]   [1, 65536, 3]  
        

        # æ¸²æŸ“è¿”å›žå­—å…¸  renderåº”è¯¥æ˜¯ç”¨æ¥æ¸²æŸ“çš„  from agents.manigaussian_bc2.gaussian_renderer import render
        render_return_dict = render_mask(
            data, i, xyz_i, rot_i, scale_i, opacity_i, 
            bg_color=bg_color, pts_rgb=None, features_color=feature_i, features_language=feature_language_i,
            precomputed_mask = precomputed_mask_i,
            )

        # .unsqueeze(0): è¿™æ˜¯PyTorchå¼ é‡çš„ä¸€ä¸ªæ“ä½œï¼Œç”¨äºŽåœ¨å¼ é‡çš„ç¬¬0ä¸ªç»´åº¦ï¼ˆå³æœ€å‰é¢ï¼‰å¢žåŠ ä¸€ä¸ªç»´åº¦ã€‚å¦‚æžœåŽŸå§‹å¼ é‡æ˜¯ä¸€ç»´çš„ï¼Œè¿™ä¸ªæ“ä½œä¼šå°†å…¶å˜æˆäºŒç»´çš„ï¼Œå…¶ä¸­æ–°åŠ çš„ç»´åº¦å¤§å°ä¸º1ã€‚
        # data['novel_view']['img_pred']: è¿™æ˜¯åœ¨ data å­—å…¸ä¸­çš„ 'novel_view' é”®ä¸‹åˆ›å»ºæˆ–æ›´æ–°ä¸€ä¸ªå­é”® 'img_pred'ã€‚è¿™ä¸ªå­é”®è¢«èµ‹å€¼ä¸º render_return_dict['render'] å¼ é‡å¢žåŠ ä¸€ä¸ªæ–°ç»´åº¦åŽçš„ç»“æžœã€‚
        data['novel_view']['mask_pred'] = render_return_dict['mask'].unsqueeze(0)
        data['novel_view']['embed_pred'] = render_return_dict['render_embed'].unsqueeze(0)
        return data

    def pts2render_rgb(self, data: dict, bg_color=[0,0,0]):
        '''use render function in GSZ åœ¨GSZ ä¸­ä½¿ç”¨æ¸²æŸ“åŠŸèƒ½(åº”è¯¥å°±æ˜¯ä½¿ç”¨å…ˆå‰é‡‡é›†çš„æ•°æ®é‡å»ºåœºæ™¯)'''
        bs = data['intr'].shape[0]
        assert bs == 1, "batch size should be 1"
        # å…¬å¼2ä¸­ æ—¶åˆ»i çš„çŠ¶æ€ï¼ˆÎ¸ å¤šäº†f é«˜çº§è¯­ä¹‰ç‰¹å¾ï¼‰
        i = 0
        xyz_i = data['xyz_maps'][i, :, :].detach() 
        feature_i = data['sh_maps'][i, :, :, :].detach()  # [16384, 4, 3]
        rot_i = data['rot_maps'][i, :, :].detach() 
        scale_i = data['scale_maps'][i, :, :].detach() 
        opacity_i = data['opacity_maps'][i, :, :].detach() 
        # precomputed_mask_i = data['mask_maps'][i, :, :] # mask  [1, 65536, 3]
        feature_language_i = data['feature_maps'][i, :, :].detach()   # [B, N, 3]   [1, 65536, 3]  
        

        # æ¸²æŸ“è¿”å›žå­—å…¸  renderåº”è¯¥æ˜¯ç”¨æ¥æ¸²æŸ“çš„  from agents.manigaussian_bc2.gaussian_renderer import render
        render_return_dict = render_rgb(
            data, i, xyz_i, rot_i, scale_i, opacity_i, 
            bg_color=bg_color, pts_rgb=None, features_color=feature_i, features_language=feature_language_i,
            # precomputed_mask = precomputed_mask_i,
            )

        # .unsqueeze(0): è¿™æ˜¯PyTorchå¼ é‡çš„ä¸€ä¸ªæ“ä½œï¼Œç”¨äºŽåœ¨å¼ é‡çš„ç¬¬0ä¸ªç»´åº¦ï¼ˆå³æœ€å‰é¢ï¼‰å¢žåŠ ä¸€ä¸ªç»´åº¦ã€‚å¦‚æžœåŽŸå§‹å¼ é‡æ˜¯ä¸€ç»´çš„ï¼Œè¿™ä¸ªæ“ä½œä¼šå°†å…¶å˜æˆäºŒç»´çš„ï¼Œå…¶ä¸­æ–°åŠ çš„ç»´åº¦å¤§å°ä¸º1ã€‚
        # data['novel_view']['img_pred']: è¿™æ˜¯åœ¨ data å­—å…¸ä¸­çš„ 'novel_view' é”®ä¸‹åˆ›å»ºæˆ–æ›´æ–°ä¸€ä¸ªå­é”® 'img_pred'ã€‚è¿™ä¸ªå­é”®è¢«èµ‹å€¼ä¸º render_return_dict['render'] å¼ é‡å¢žåŠ ä¸€ä¸ªæ–°ç»´åº¦åŽçš„ç»“æžœã€‚
        data['mask_view']['rgb_pred'] = render_return_dict['render'].unsqueeze(0)
        # data['novel_view']['embed_pred'] = render_return_dict['render_embed'].unsqueeze(0)
        return data



    def pts2render_mask_gen(self, data: dict, bg_color=[0,0,0]):
        '''use render function in GSZ åœ¨GSZ ä¸­ä½¿ç”¨æ¸²æŸ“åŠŸèƒ½(åº”è¯¥å°±æ˜¯ä½¿ç”¨å…ˆå‰é‡‡é›†çš„æ•°æ®é‡å»ºåœºæ™¯)'''
        bs = data['intr'].shape[0]
        assert bs == 1, "batch size should be 1"
        # å…¬å¼2ä¸­ æ—¶åˆ»i çš„çŠ¶æ€ï¼ˆÎ¸ å¤šäº†f é«˜çº§è¯­ä¹‰ç‰¹å¾ï¼‰
        i = 0
        xyz_i = data['xyz_maps'][i, :, :].detach()       # [65536, 3]
        feature_i = data['sh_maps'][i, :, :, :].detach()  # [16384(çŽ°åœ¨åº”è¯¥æ˜¯256 * 256), 4, 3]
        rot_i = data['rot_maps'][i, :, :].detach() 
        scale_i = data['scale_maps'][i, :, :].detach() 
        opacity_i = data['opacity_maps'][i, :, :].detach() 
        precomputed_mask_i = data['mask_maps'][i, :, :] # mask  [1, 65536, 3]
        # precomputed_mask_i = precomputed_mask_i.reshape(1,256,256,3).permute(0,3,1,2) # [1, 65536, 3] -> [1, 3, 256, 256]
        # if self.mask_gen =='pre':    
        #     precomputed_mask_i = F.interpolate(precomputed_mask_i, size=(128, 128), mode='bilinear', align_corners=False) # [1 3 256 256] -> [1 3 128 128]
        # precomputed_mask_i = precomputed_mask_i.squeeze(0).permute(1,2,0)
        
        feature_language_i = data['feature_maps'][i, :, :].detach()   # [B, N, 3]   [1, 65536, 3]  
        

        # æ¸²æŸ“è¿”å›žå­—å…¸  renderåº”è¯¥æ˜¯ç”¨æ¥æ¸²æŸ“çš„  from agents.manigaussian_bc2.gaussian_renderer import render
        render_return_dict = render_mask_gen(
            data, i, xyz_i, rot_i, scale_i, opacity_i, 
            bg_color=bg_color, pts_rgb=None, features_color=feature_i, features_language=feature_language_i,
            precomputed_mask = precomputed_mask_i,
            )

        # .unsqueeze(0): è¿™æ˜¯PyTorchå¼ é‡çš„ä¸€ä¸ªæ“ä½œï¼Œç”¨äºŽåœ¨å¼ é‡çš„ç¬¬0ä¸ªç»´åº¦ï¼ˆå³æœ€å‰é¢ï¼‰å¢žåŠ ä¸€ä¸ªç»´åº¦ã€‚å¦‚æžœåŽŸå§‹å¼ é‡æ˜¯ä¸€ç»´çš„ï¼Œè¿™ä¸ªæ“ä½œä¼šå°†å…¶å˜æˆäºŒç»´çš„ï¼Œå…¶ä¸­æ–°åŠ çš„ç»´åº¦å¤§å°ä¸º1ã€‚
        # data['novel_view']['img_pred']: è¿™æ˜¯åœ¨ data å­—å…¸ä¸­çš„ 'novel_view' é”®ä¸‹åˆ›å»ºæˆ–æ›´æ–°ä¸€ä¸ªå­é”® 'img_pred'ã€‚è¿™ä¸ªå­é”®è¢«èµ‹å€¼ä¸º render_return_dict['render'] å¼ é‡å¢žåŠ ä¸€ä¸ªæ–°ç»´åº¦åŽçš„ç»“æžœã€‚
        data['novel_view']['mask_gen'] = render_return_dict['mask'].unsqueeze(0)
        data['novel_view']['embed_pred'] = render_return_dict['render_embed'].unsqueeze(0)
        return data

    def createby_gt_mask(self, data: dict, gt_mask=None, gt_mask_camera_extrinsic=None, gt_mask_camera_intrinsic=None, next_gt_mask = None,
                gt_maskdepth=None,next_gt_maskdepth=None):
        # print("only for gen",gt_mask_camera_intrinsic)
        # assert bs == 1, "batch size should be 1" # è¦æ£€æµ‹å—ï¼Ÿ
        front_intrinsic = gt_mask_camera_intrinsic[0] # [tensor([[[-351.6771,    0.0000,  128.0000], 
        overhead_intrinsic = gt_mask_camera_intrinsic[1]
        # print("gt_mask_camera_intrinsic",gt_mask_camera_intrinsic)
        # print("gt_mask_camera_extrinsic",gt_mask_camera_extrinsic)
        # front_mask = gt_mask[0]
        # overhead_mask = gt_mask[1]
        # front_depth = gt_maskdepth[0]
        # overhead_depth = gt_maskdepth[1]
        # # .squeeze(0) or [0]
        # # # ä¸‰ç»´æ˜ å°„åˆ°äºŒç»´ ä½†æ˜¯depthçš„å†™çš„è¿˜æ˜¯æœ‰é—®é¢˜
        # # newxyz_front = label_point_cloud(data['xyz'][0],front_depth,front_intrinsic,front_mask) # åº”è¯¥æœ‰è¿™ä¸ªå­˜ç€çš„å§
        # # newxyz_overhead = label_point_cloud(data['xyz'][0],overhead_depth,overhead_intrinsic,overhead_mask)
        # # print(newxyz_overhead) # []
        # # å·¦è‡‚çš„ç‚¹äº‘
        # leftxyz_front = depth_mask_to_3d(front_depth,front_mask,front_intrinsic)
        # leftxyz_overhead = depth_mask_to_3d(overhead_depth,overhead_mask,overhead_intrinsic)
        # leftxyz = np.concatenate((leftxyz_front, leftxyz_overhead), axis=0) # æˆ–è€…ç›¸åŠ 
        # leftxyz = torch.tensor(leftxyz)
        # if len(leftxyz) > 0:
        #     mask_3d = points_inside_convex_hull(data['xyz'][0].detach(), leftxyz)
        # # if len(leftxyz_overhead) > 0:
        #     # mask_3d_overhead = points_inside_convex_hull(data['xyz'][0].detach(), leftxyz_overhead)

        mask_3d = None
        # # --------ä¸Šé¢éƒ¨åˆ†æ˜¯çŽ°åœ¨é˜¶æ®µçš„å†™æ³•ï¼Œè€—æ—¶ä¹…ï¼Œæ³¨é‡Šäº†---------------------------------------now -----------------------------------------------------

        # front_intrinsic = gt_mask_camera_intrinsic[0] # [tensor([[[-351.6771,    0.0000,  128.0000], 
        # overhead_intrinsic = gt_mask_camera_intrinsic[1]
        # time1 = time.perf_counter()
        # print('1 time', time1)
        next_front_mask = next_gt_mask[0]
        next_overhead_mask = next_gt_mask[1]
        next_front_depth = next_gt_maskdepth[0]
        next_overhead_depth = next_gt_maskdepth[1]
        # .squeeze(0) or [0]

        # å·¦è‡‚çš„ç‚¹äº‘ å‰è§†è§’ 0.15s
        next_leftxyz_front = depth_mask_to_3d(next_front_depth,next_front_mask,front_intrinsic)
        
        # time2 = time.perf_counter()
        # time_step1 = time2 - time1
        # print(f"time2 = {time2} step1 = {time_step1:.2f}s")    # 0.15s    
        
        # å·¦è‡‚çš„ç‚¹äº‘ ä¸Šè§†è§’
        next_leftxyz_overhead = depth_mask_to_3d(next_overhead_depth,next_overhead_mask,overhead_intrinsic)
        
        # time3 = time.perf_counter()
        # time_step2 = time3 - time2
        # print(f"time3 = {time3} step2 = {time_step2:.2f}s") # 0.12s

        # ç›¸åŠ     
        # # CPU
        # next_leftxyz = merge_arrays(next_leftxyz_front, next_leftxyz_overhead) # æˆ–è€…ç›¸åŠ 
        # next_leftxyz = torch.tensor(next_leftxyz)
        # GPU
        next_leftxyz = merge_tensors(next_leftxyz_front, next_leftxyz_overhead).cpu()
    
        # time4 = time.perf_counter()
        # time_step3 = time4 - time3
        # print(f"time4 = {time4} step3 = {time_step3:.2f}s") # CPU 0.55s GPU:0s?

        if len(next_leftxyz) > 0:
            # next_mask_3d = points_inside_convex_hull( data['canon_xyz'][0].detach(), next_leftxyz)
            next_mask_3d = points_inside_convex_hull( data['xyz'][0].detach(), next_leftxyz)
        
        # time5 = time.perf_counter()
        # time_step4 = time5 - time4
        # print(f"time5 = {time5} step4 = {time_step4:.2f}s") # 0.55s

        return mask_3d, next_mask_3d

    def generate_final_class_labels(self,next_left_mask_gen):
        """
        æŽ’é™¤å·¦æ‰‹åŒºåŸŸã€‚ 1 128 128 3 ->
        """
        # èŽ·å–æ¯ä¸ªåƒç´ çš„æœ€å¤§ç±»ç´¢å¼•
        # exclude_left_mask = (next_left_mask_gen > 2.5) | (next_left_mask_gen < 1.5) # åŽŸæ¥ å€¼çš„æ–¹å¼æ¥åˆ¤æ–­
        # print("before",next_left_mask_gen.shape)
        class_indices = torch.argmax(next_left_mask_gen, dim=-1)
        # print("class_indices = ", class_indices.shape,class_indices)

        # åˆå§‹åŒ–æœ€ç»ˆçš„åˆ†ç±»æ ‡ç­¾
        # final_class_labels = torch.zeros_like(class_indices, dtype=torch.long)
        # # è®¾ç½®èƒŒæ™¯ã€å³æ‰‹å’Œå·¦æ‰‹çš„æ ‡ç­¾
        # final_class_labels[class_indices == 0] = 0  # èƒŒæ™¯
        # final_class_labels[class_indices == 1] = 1  # å³æ‰‹
        # final_class_labels[class_indices == 2] = 2  # å·¦æ‰‹

        # ç”ŸæˆæŽ’é™¤å·¦æ‰‹çš„ mask
        # exclude_left_mask = final_class_labels != 2

        exclude_left_mask = class_indices != 2  # ä¸ç­‰äºŽ 2 çš„éƒ¨åˆ†ä¸º True
        # print("exclude_left_mask = ", exclude_left_mask.shape,exclude_left_mask)

        # return final_class_labels, exclude_left_mask
        return exclude_left_mask

    def generate_final_class_labels_ce1(self,next_left_mask_gen):
        """
        åŽ»é™¤èƒŒæ™¯lossè®¡ç®—çš„(label-1) æŽ’é™¤å·¦æ‰‹åŒºåŸŸã€‚ 1 128 128 3 -> 1 128 128 2 -> out: 1 128 128 [T:1 / F:0]
        """
        # èŽ·å–æ¯ä¸ªåƒç´ çš„æœ€å¤§ç±»ç´¢å¼•
        # exclude_left_mask = (next_left_mask_gen > 2.5) | (next_left_mask_gen < 1.5) # åŽŸæ¥ å€¼çš„æ–¹å¼æ¥åˆ¤æ–­
        # print("before",next_left_mask_gen.shape)
        next_left_mask_gen = next_left_mask_gen[:,:,:,[0,1]]
        class_indices = torch.argmax(next_left_mask_gen, dim=-1)
        print("class_indices = ", class_indices.shape,class_indices)

        exclude_left_mask = class_indices != 1  # ä¸ç­‰äºŽ 2 çš„éƒ¨åˆ†ä¸º True

        return exclude_left_mask


    def generate_final_class_labels_L1(self,next_left_mask_gen):
        """ [1 128 128 3] -> [1 128 128 3] [True False]       """
        class_indices = next_left_mask_gen.mean(dim=-1)
        print("class_indices = ", class_indices.shape,class_indices)
        next_left_mask_gen = next_left_mask_gen.squeeze(-1)
        exclude_left_mask = torch.ones_like(next_left_mask_gen, dtype=torch.float32)
        exclude_left_mask = (class_indices < 1.5) # 2æ˜¯å·¦æ‰‹
        exclude_left_mask = exclude_left_mask.unsqueeze(-1).repeat(1,1,1,3)   
        print("exclude_left_mask",exclude_left_mask)
        # exclude_left_mask = class_indices != 2  # ä¸ç­‰äºŽ 2 çš„éƒ¨åˆ†ä¸º True
        return exclude_left_mask
    
    def mask_onehot(self,mask):
        """1 128 128 1 -> [1 128 128 3] 100 010 001"""
        right_min, right_max, left_min, left_max = 53, 73, 94, 114
        # print("gt_mask",mask,mask.shape)
        gt_mask1 = mask.squeeze(-1)
        # print("gt_mask1",gt_mask1,gt_mask1.shape) # [1,256,256]

        # åˆå§‹åŒ–ç‹¬çƒ­ç¼–ç å¼ é‡ bg:[0,0,0]   right:[0,1,0]  left:[0,0,1]
        gt_mask_label = torch.zeros((*gt_mask1.shape, self.num_classes), dtype=torch.float32) 
        # print("gt_mask_label.shape",gt_mask_label.shape) # [1,256,256,3]
        # å°†æ ‡ç­¾è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç 
        bg_mask = (gt_mask1 < right_min) | ((gt_mask1 > right_max) & (gt_mask1 < left_min)) | (gt_mask1 > left_max)
        # print("bg_mask",bg_mask.shape)
        gt_mask_label[bg_mask] = torch.tensor([1, 0, 0], dtype=torch.float32)
       
        right_mask = (gt_mask1 > right_min - 1) & (gt_mask1 < right_max + 1)
        gt_mask_label[right_mask] = torch.tensor([0, 1, 0], dtype=torch.float32)  # å³æ‰‹çš„ç‹¬çƒ­ç¼–ç                   
        left_mask = (gt_mask1 > left_min - 1) & (gt_mask1 < left_max + 1)
        gt_mask_label[left_mask] = torch.tensor([0, 0, 1], dtype=torch.float32) 


        """ # # Tensorå†™æ³•ï¼ˆmaskæ ‡ç­¾å½’ç±» 0ï¼šbg    1:ritght    2:leftï¼‰
        # # gt_mask_label = torch.zeros_like(gt_mask, dtype=torch.uint8)
        # gt_mask_label = torch.zeros_like(gt_mask, dtype=torch.long)
        # gt_mask_label[(gt_mask > right_min-1) & (gt_mask < right_max+1)] = 1
        # gt_mask_label[(gt_mask > left_min-1) & (gt_mask < left_max+1)] = 2
        # # next_gt_mask_label = torch.zeros_like(next_gt_mask, dtype=torch.uint8)
        # next_gt_mask_label = torch.zeros_like(next_gt_mask, dtype=torch.long)
        # next_gt_mask_label[(next_gt_mask > right_min-1) & (next_gt_mask < right_max+1)] = 1
        # next_gt_mask_label[(next_gt_mask > left_min-1) & (next_gt_mask < left_max+1)] = 2



        # gt_mask_label = torch.clamp(gt_mask_label, 0, 1)
                        # # gt_mask = gt_mask[indx].permute(0, 2, 3, 1).repeat(1, 1, 1, 3)  # å¤åˆ¶ä¸‰æ¬¡ï¼Œå¾—åˆ° [1,128, 128, 3]
                        # gt_mask = gt_mask.repeat(1, 3, 1, 1)  #  [1,3,256,256]
                        # # gt_mask = F.interpolate(gt_mask, size=(128, 128), mode='bilinear', align_corners=False).permute(0, 2, 3, 1)
                        # # next_gt_mask = next_gt_mask[indx].permute(0, 2, 3, 1).repeat(1, 1, 1, 3)
                        # next_gt_mask = next_gt_mask.repeat(1, 3, 1, 1)  #  [1,3,256,256]
                        # # next_gt_mask = F.interpolate(next_gt_mask, size=(128, 128), mode='bilinear', align_corners=False).permute(0, 2, 3, 1)
                        # gt_mask = gt_mask.repeat(1, 1, 1, self.num_classes)  #  [1,256,256,3]
                        # next_gt_mask = next_gt_mask.repeat(1, 1, 1, self.num_classes)
                        # print("gt_mask",gt_mask,gt_mask.shape)
                        # gt_mask1 = gt_mask.squeeze(-1)
                        # print("gt_mask1",gt_mask1,gt_mask1.shape) # [1,256,256]
                        # gt_mask = gt_mask.repeat(1, 1, 1, 3)
                        # # åˆå§‹åŒ–ç‹¬çƒ­ç¼–ç å¼ é‡ bg:[0,0,0]   right:[0,1,0]  left:[0,0,1]
                        # gt_mask_label = torch.zeros((*gt_mask1.shape, self.num_classes), dtype=torch.float32) 
                        # print("gt_mask_label.shape",gt_mask_label.shape) # [1,256,256,3]
                        # # å°†æ ‡ç­¾è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç 
                        # bg_mask = (gt_mask1 < right_min) | ((gt_mask1 > right_max) & (gt_mask1 < left_min)) | (gt_mask1 > left_max)
                        # print("bg_mask",bg_mask.shape)
                        # # bg_mask_expanded = bg_mask.expand(-1, -1, -1, 3)
                        # # gt_mask_label[bg_mask_expanded] = torch.tensor([1, 0, 0], dtype=torch.float32)
                        # gt_mask_label[bg_mask] = torch.tensor([1, 0, 0], dtype=torch.float32)
                        # # gt_mask_label[(gt_mask1 < right_min) | ((gt_mask1 > right_max) & (gt_mask1 < left_min) | (gt_mask1 > left_max)), 0] = 1  # èƒŒæ™¯
                        
                        # right_mask = (gt_mask1 > right_min - 1) & (gt_mask1 < right_max + 1)
                        # # right_mask_expanded = right_mask.expand(-1, -1, -1, 3)
                        # # gt_mask_label[right_mask_expanded] = torch.tensor([0, 1, 0], dtype=torch.float32)  # å³æ‰‹çš„ç‹¬çƒ­ç¼–ç 
                        # gt_mask_label[right_mask] = torch.tensor([0, 1, 0], dtype=torch.float32)  # å³æ‰‹çš„ç‹¬çƒ­ç¼–ç 
                        # # gt_mask_label[(gt_mask1 > right_min-1) & (gt_mask1 < right_max+1), 1] = 1  # å³æ‰‹

                        # # gt_mask_label[(gt_mask1 > left_min-1) & (gt_mask1 < left_max+1), 2] = 1  # å·¦æ‰‹                        
                        # left_mask = (gt_mask1 > left_min - 1) & (gt_mask1 < left_max + 1)
                        # # left_mask_expanded = left_mask.expand(-1, -1, -1, 3)
                        # # gt_mask_label[left_mask_expanded] = torch.tensor([0, 0, 1], dtype=torch.float32) 
                        # gt_mask_label[left_mask] = torch.tensor([0, 0, 1], dtype=torch.float32) 

                        # print("gt_mask_label",gt_mask_label, gt_mask_label.shape)

                        # # next_gt_mask_label åŒç†
                        # next_gt_mask_label = torch.zeros((*next_gt_mask.shape, num_classes), dtype=torch.float32)
                        # next_gt_mask_label[(next_gt_mask < right_min) | ((next_gt_mask > right_max) & (next_gt_mask < left_min) | (next_gt_mask > left_max)), 0] = 1  # èƒŒæ™¯
                        # next_gt_mask_label[(next_gt_mask > right_min-1) & (next_gt_mask < right_max+1), 1] = 1  # å³æ‰‹
                        # next_gt_mask_label[(next_gt_mask > left_min-1) & (next_gt_mask < left_max+1), 2] = 1  # å·¦æ‰‹ """

        return gt_mask_label

    def mask_label_onehot(self,gt_mask):
        """[1 128 128 1] -> [1 128 128]  maskæ ‡ç­¾å½’ç±» 0ï¼šbg    1:ritght    2:left"""
        right_min, right_max, left_min, left_max = 53, 73, 94, 114

        # Tensorå†™æ³•ï¼ˆmaskæ ‡ç­¾å½’ç±» 0ï¼šbg    1:ritght    2:leftï¼‰
        # gt_mask_label = torch.zeros_like(gt_mask, dtype=torch.uint8)
        # gt_mask = gt_mask.squeeze(-1)
        gt_mask_label = torch.zeros_like(gt_mask, dtype=torch.long)
        gt_mask_label[(gt_mask > right_min-1) & (gt_mask < right_max+1)] = 1
        gt_mask_label[(gt_mask > left_min-1) & (gt_mask < left_max+1)] = 2
        gt_mask_label = gt_mask_label.squeeze(-1)
        # # next_gt_mask_label = torch.zeros_like(next_gt_mask, dtype=torch.uint8)
        # next_gt_mask_label = torch.zeros_like(next_gt_mask, dtype=torch.long)
        # next_gt_mask_label[(next_gt_mask > right_min-1) & (next_gt_mask < right_max+1)] = 1
        # next_gt_mask_label[(next_gt_mask > left_min-1) & (next_gt_mask < left_max+1)] = 2
        
        return gt_mask_label

    def mask_label(self,gt_mask):
        """[1 128 128 1] -> [1 128 128 3] [000 / 111 / 222]"""
        right_min, right_max, left_min, left_max = 53, 73, 94, 114

        # Tensorå†™æ³•ï¼ˆmaskæ ‡ç­¾å½’ç±» 0ï¼šbg    1:ritght    2:leftï¼‰
        # gt_mask_label = torch.zeros_like(gt_mask, dtype=torch.uint8)
        gt_mask = gt_mask.squeeze(-1)
        gt_mask_label = torch.zeros_like(gt_mask, dtype=torch.float32)
        gt_mask_label[(gt_mask > right_min-1) & (gt_mask < right_max+1)] =1.0
        gt_mask_label[(gt_mask > left_min-1) & (gt_mask < left_max+1)] = 2.0
        gt_mask_label = gt_mask_label.unsqueeze(-1).repeat(1,1,1,3)         
        return gt_mask_label


    def vis_labels(self,next_left_mask_gen):
        """
        vis [1 128 128 3] - > rgb
        """
        # èŽ·å–æ¯ä¸ªåƒç´ çš„æœ€å¤§ç±»ç´¢å¼•
        class_indices = torch.argmax(next_left_mask_gen, dim=-1)
        print("class_indices = ", class_indices.shape,class_indices)

        # # åˆå§‹åŒ–æœ€ç»ˆçš„åˆ†ç±»æ ‡ç­¾
        # final_class_labels = torch.zeros_like(class_indices, dtype=torch.long)
        # # # è®¾ç½®èƒŒæ™¯ã€å³æ‰‹å’Œå·¦æ‰‹çš„æ ‡ç­¾
        # final_class_labels[class_indices == 0] = 0  # èƒŒæ™¯
        # final_class_labels[class_indices == 1] = 1  # å³æ‰‹
        # final_class_labels[class_indices == 2] = 2  # å·¦æ‰‹
        color_image = torch.zeros((*class_indices.shape, 3), dtype=torch.uint8)

        # ä¸ºæ¯ä¸ªç±»åˆ«è®¾ç½®é¢œè‰²ï¼ˆRGBï¼‰
        color_image[class_indices == 0] = torch.tensor([0, 0, 0], dtype=torch.uint8)    # èƒŒæ™¯ - é»‘è‰²
        color_image[class_indices == 1] = torch.tensor([255, 0, 0], dtype=torch.uint8)  # å³æ‰‹ - çº¢è‰²
        color_image[class_indices == 2] = torch.tensor([0, 0, 255], dtype=torch.uint8)  # å·¦æ‰‹ - è“è‰²

        # ç”ŸæˆæŽ’é™¤å·¦æ‰‹çš„ mask
        # exclude_left_mask = final_class_labels != 2
        return color_image

    def vis_labels_ce1(self,next_left_mask_gen):
        """
        (å‡åŽ»bglossè®¡ç®—) vis [1 128 128 3] -> [1 128 128 2] - > rgb
        """
        # èŽ·å–æ¯ä¸ªåƒç´ çš„æœ€å¤§ç±»ç´¢å¼•
        next_left_mask_gen = next_left_mask_gen[:,:,:,[0,1]]
        class_indices = torch.argmax(next_left_mask_gen, dim=-1)
        print("class_indices1 128 128 2 = ", class_indices.shape,class_indices)

        color_image = torch.zeros((*class_indices.shape, 3), dtype=torch.uint8)

        # ä¸ºæ¯ä¸ªç±»åˆ«è®¾ç½®é¢œè‰²ï¼ˆRGBï¼‰
        # color_image[class_indices == 0] = torch.tensor([0, 0, 0], dtype=torch.uint8)    # èƒŒæ™¯ - é»‘è‰²
        color_image[class_indices == 0] = torch.tensor([255, 0, 0], dtype=torch.uint8)  # å³æ‰‹ - çº¢è‰²
        color_image[class_indices == 1] = torch.tensor([0, 0, 255], dtype=torch.uint8)  # å·¦æ‰‹ - è“è‰²
        return color_image


    def vis_labelsL1(self,mask):
        """
        vis [1 128 128 3] - > rgb
        """
        mask_mean = mask.mean(dim=-1)
        print("vis_labelsL1 mask_mean =",mask_mean.shape,mask_mean)
        mask_rgb = torch.zeros((mask.shape[0], mask.shape[1], mask.shape[2], 3), dtype=torch.uint8)
        # è®¾ç½®é¢œè‰²èŒƒå›´
        # mask_rgb[(mask_mean >= 0) & (mask_mean < 0.5)] = torch.tensor([0, 0, 0], dtype=torch.uint8)    # é»‘è‰²
        mask_rgb[(mask_mean >= 0.7) & (mask_mean < 1.3)] = torch.tensor([255, 0, 0], dtype=torch.uint8) # çº¢è‰²
        mask_rgb[mask_mean >= 1.3] = torch.tensor([0, 0, 255], dtype=torch.uint8)                       # Green 
        # mask_rgb[(mask_mean >= 0.5) & (mask_mean < 1.5)] = torch.tensor([255, 0, 0], dtype=torch.uint8) # çº¢è‰²
        # mask_rgb[mask_mean >= 1.5] = torch.tensor([0, 0, 255], dtype=torch.uint8)                       # Green
        return mask_rgb

    def one_hot_encode(self,mask, num_classes):
        "b h w -> b c h w c=(100 010 001)"
        # mask çš„å½¢çŠ¶ä¸º (batch_size, height, width)ï¼Œæ•°å€¼ä¸ºç±»åˆ«
        # è½¬æ¢ä¸º One-Hot ç¼–ç ï¼Œç»“æžœå½¢çŠ¶ä¸º (batch_size, num_classes, height, width)
        one_hot_mask = torch.nn.functional.one_hot(mask, num_classes=num_classes)
        one_hot_mask = one_hot_mask.permute(0, 3, 1, 2)  # è°ƒæ•´ç»´åº¦é¡ºåº
        return one_hot_mask.float()  # è½¬æ¢ä¸ºæµ®ç‚¹æ•°